{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to add a VTA, dynamic dopamine release and simple reinforcement learning to the connectome-based dynamical model.\n",
    "\n",
    "Sean Froudist-Walsh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's get what we need together\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import numpy.matlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas\n",
    "import scipy.io as sio\n",
    "import brian2\n",
    "import os\n",
    "import copy\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the function that transforms input current to changes in firing rate for excitatory neurons (Abbott and Chance, 2005). \n",
    "<br>\n",
    "$$r_E = \\frac{aI_{total,E} - b}{1 - e^{-d(aI_{total,E} - b)}} $$\n",
    "\n",
    "Update the firing rates of the interneurons using a threshold linear input/output function\n",
    "$$ \\begin{cases}\n",
    "  r_I = c_II_{total,I} + r_0 & \\text{for } I_{total,I}\\ge -r_0/c_I\\\\    \n",
    "  r_I = 0     & \\text{otherwise }  \n",
    "\\end{cases} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def current_to_frequency(input_current,population_type,parameters):\n",
    "    if population_type == 'E':\n",
    "        a = parameters['a_e']\n",
    "        b = parameters['b_e']\n",
    "        d = parameters['d_e']\n",
    "        return np.divide((a*input_current - b),(1 - np.exp(-d*(a*input_current - b))))\n",
    "    if population_type == 'PV':\n",
    "        c_I = parameters['c_I_pv']\n",
    "        r_0 = parameters['r_0_pv']\n",
    "        r = np.maximum(c_I*input_current + r_0,0)\n",
    "        return r\n",
    "    if population_type == 'SST':\n",
    "        c_I = parameters['c_I_sst']\n",
    "        r_0 = parameters['r_0_sst']\n",
    "        r = np.maximum(c_I*input_current + r_0,0)\n",
    "        return r\n",
    "    if population_type == 'VIP':\n",
    "        c_I = parameters['c_I_vip']\n",
    "        r_0 = parameters['r_0_vip']\n",
    "        r = np.maximum(c_I*input_current + r_0,0)\n",
    "        return r\n",
    "    if population_type == 'DA':\n",
    "        c_I = parameters['c_I_da']\n",
    "        r_0 = parameters['r_0_da']\n",
    "        r = np.maximum(c_I*input_current + r_0,0)\n",
    "        return r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the current formulation of the dendrite input-output function (presuming $I_{inh}$ is negative)\n",
    "<br>\n",
    "<br>\n",
    "$$ \n",
    "I_{soma,dendrite} = f_I(I_{exc},I_{inh}) = \n",
    "c_1.\\biggl[\\tanh\\biggl(\\dfrac{I_{exc} + c_3*I_{inh} + c_4}{c_5 e^{-I_{inh}/c6}}\\biggr)\\biggr] + c_2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dendrite_input_output(exc_current,inh_current,parameters):\n",
    "    c1 = parameters['c1']\n",
    "    c2 = parameters['c2']\n",
    "    c3 = parameters['c3']\n",
    "    c4 = parameters['c4']\n",
    "    c5 = parameters['c5']\n",
    "    c6 = parameters['c6']\n",
    "    \n",
    "    beta = c5*np.exp(-inh_current/c6)\n",
    "    \n",
    "    return c1*(np.tanh((exc_current +c3*inh_current + c4)/beta)) + c2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the NMDA derivative\n",
    "<br>\n",
    "$$ \\frac{dS_{NMDA}}{dt} = -\\frac{S_{NMDA}}{\\tau_{NMDA}} + x_0u_0(1 - S_{NMDA})\\gamma r_E$$\n",
    "(Wong & Wang, 2006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NMDA_deriv(S_NMDA_prev,rate_now,parameters):\n",
    "    \n",
    "    return -S_NMDA_prev/parameters['tau_nmda'] + parameters['x0']*parameters['u0']*parameters['gamma_nmda']*(1 - S_NMDA_prev)*rate_now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the AMPA derivative \n",
    "<br>\n",
    "$$ \\frac{dS_{AMPA}}{dt} = -\\frac{S_{AMPA}}{\\tau_{AMPA}} + x_0u_0\\gamma_{AMPA}r_E$$\n",
    "(Wong & Wang, 2006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AMPA_deriv(S_AMPA_prev,rate_now,parameters):\n",
    "    \n",
    "    return -S_AMPA_prev/parameters['tau_ampa'] + parameters['x0']*parameters['u0']*parameters['gamma_ampa']*rate_now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the GABA derivative\n",
    "<br>\n",
    "$$ \\frac{dS_{GABA}}{dt} = -\\frac{S_{GABA}}{\\tau_{GABA}} + \\gamma_Ir_I$$\n",
    "(Wong & Wang, 2006)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GABA_deriv(S_GABA_prev,rate_now,parameters,cell_section):\n",
    "    if cell_section == 'soma':\n",
    "        return -S_GABA_prev/parameters['tau_gaba'] + parameters['gamma_gaba']*rate_now \n",
    "    elif cell_section == 'dendrite':\n",
    "        return -S_GABA_prev/parameters['tau_gaba_dend'] + parameters['gamma_gaba']*rate_now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the adaptation current derivative\n",
    "$$ \\frac{dS_{a}}{dt} = -\\frac{S_{a}}{\\tau_{a}} + r $$\n",
    "(Engel & Wang, 2001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptation_deriv(S_a_prev,rate_now,parameters):\n",
    "    return -S_a_prev/parameters['tau_adapt'] + rate_now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several of dopamine's effects are models with a sigmoid function (such as how release gets converted to fraction of occupied D1 receptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_DA(height,midpoint,slope):\n",
    "     return np.exp(slope*(height-midpoint))/(1 + np.exp(slope*(height-midpoint)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the dopamine concentration function\n",
    "$$ \\frac{d[DA]}{dt} = -\\frac{[DA]}{\\tau_{DA}} + \\gamma_{DA}r_{VTA_{DA}} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DAconc_deriv(DA_prev,DA_rate_now,parameters,brain_region):\n",
    "    if brain_region == 'cortex':\n",
    "        return -DA_prev/parameters['tau_DA_ctx'] + parameters['gamma_DA_ctx']*DA_rate_now\n",
    "    elif brain_region == 'vta':\n",
    "        return -DA_prev/parameters['tau_DA_vta'] + parameters['gamma_DA_vta']*DA_rate_now\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the short-term facilitation (usage of synaptic resources - related to presynaptic calcium\n",
    "$$ \\frac{du}{dt} = \\frac{U - u}{\\tau_{u}} + U(1-u)r $$\n",
    "(Mongillo et al., 2008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def STF_deriv(rate_prev,u_prev,parameters):\n",
    "    return (parameters['U_baseline'] - u_prev)/parameters['tau_u'] + parameters['U_baseline']*(1- u_prev)*rate_prev\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the short-term depression (total store of available vesicles) - is depleted by u (usage)\n",
    "$$ \\frac{dx}{dt} = \\frac{1 - x}{\\tau_{x}} - uxr $$\n",
    "(Mongillo et al., 2008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def STD_deriv(rate_prev,x_prev,u_prev,parameters):\n",
    "    return (1 - x_prev)/parameters['tau_x'] - u_prev*x_prev*rate_prev\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the NMDA derivative with STP\n",
    "<br>\n",
    "$$ \\frac{dS_{NMDA}}{dt} = -\\frac{S_{NMDA}}{\\tau_{NMDA}} + xu(1 - S_{NMDA})\\gamma r_E$$\n",
    "(Wong & Wang, 2006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NMDA_deriv_STP(S_NMDA_prev,rate_now,parameters,u_prev):\n",
    "    # STF only\n",
    "    return -S_NMDA_prev/parameters['tau_nmda'] + parameters['x0']*u_prev*parameters['gamma_nmda']*(1 - S_NMDA_prev)*rate_now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the AMPA derivative with STP\n",
    "<br>\n",
    "$$ \\frac{dS_{AMPA}}{dt} = -\\frac{S_{AMPA}}{\\tau_{AMPA}} + xu\\gamma_{AMPA}r_E$$\n",
    "(Wong & Wang, 2006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AMPA_deriv_STP(S_AMPA_prev,rate_now,parameters,u_prev):\n",
    "    # STF only\n",
    "    return -S_AMPA_prev/parameters['tau_ampa'] + parameters['x0']*u_prev*parameters['gamma_ampa']*rate_now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = {# dendrite I/O function parameters\n",
    "\t\t  'c1': 120 * brian2.pA,\n",
    "          'c2': 136.24 * brian2.pA,\n",
    "          'c3': 7.0,\n",
    "          'c4': 0 * brian2.pA,\n",
    "          'c5': 9.64 * brian2.pA,\n",
    "          'c6': 20 * brian2.pA,\n",
    "          # Time constants\n",
    "          'tau_nmda': 60 * brian2.ms,\n",
    "          'tau_gaba': 5 * brian2.ms,\n",
    "          'tau_gaba_dend': 10 * brian2.ms,\n",
    "          'tau_ampa': 2 * brian2.ms,\n",
    "          'tau_rates': 2 * brian2.ms,\n",
    "          'tau_adapt': 0.1   * brian2.second, # new\n",
    "          'tau_DA_ctx': 2      * brian2.second, # DA reuptake (slow in cortex)\n",
    "          'tau_DA_vta': 0.0005      * brian2.second, # DA reuptake (fast in vta)\n",
    "          'tau_u': 0.2 * brian2.second, # s - facilitation\n",
    "          'tau_x': 0.2 * brian2.second, # s - depressing \n",
    "          'u0': 0.22, # baseline u\n",
    "          'x0': 0.87, # baseline x              \n",
    "          'U_baseline': 0.2,\n",
    "          # f-I curve parameters - E populations\n",
    "          'a_e': 0.5 * 0.27 * brian2.Hz / brian2.pA,\n",
    "          'b_e': 0.5 * 108 * brian2.Hz,\n",
    "          'd_e': 2 * 0.154 * brian2.second,\n",
    "\t\t  # f-I curve parameters - I populations\n",
    "          'c_I_pv': 330 * brian2.Hz / brian2.nA,\n",
    "          'c_I_sst': 132 * brian2.Hz / brian2.nA,\n",
    "          'c_I_vip': 132 * brian2.Hz / brian2.nA,\n",
    "          'c_I_da': 50 * brian2.Hz / brian2.nA,\n",
    "          # firing rate params\n",
    "          'r_0_e': 5 * brian2.Hz,\n",
    "          'r_0_pv': -95 * brian2.Hz,\n",
    "          'r_0_sst': -33 * brian2.Hz,\n",
    "          'r_0_vip': -33 * brian2.Hz,\n",
    "          'r_0_da': -5 * brian2.Hz,\n",
    "    \n",
    "          # rise rates\n",
    "          'gamma_nmda': 5*0.641 * 2,\n",
    "          'gamma_gaba': 2,\n",
    "          'gamma_ampa': 5*5,                       # unitless\n",
    "          'gamma_DA_ctx': 0.1, #amount of DA released in responsed to VTA DA neuron firing\n",
    "          'gamma_DA_vta': 500, #amount of DA released in responsed to VTA DA neuron firing\n",
    "\n",
    "          # local strengths E-->\n",
    "          'g_e_self': 0.18 * brian2.nA,\n",
    "          'g_e_cross': 0 * brian2.nA,\n",
    "          'g_pv_e' : 0.174   * brian2.nA,  # E-->I strengths missing from Dan's code\n",
    "          'g_sst_e_self' : 0.0435   * brian2.nA,  \n",
    "          'g_sst_e_cross' : 0.0435   * brian2.nA,  \n",
    "          'g_vip_e' : 0.058   * brian2.nA,  \n",
    "          # local strengths PV-->\n",
    "          'g_e_pv_min': -0.001 * brian2.nA, # dopamine dependent min PV->E strength\n",
    "          'g_e_pv_max': -0.4 * brian2.nA, # dopamine dependent max PV->E strength\n",
    "          'g_pv_self': -0.18 * brian2.nA,\n",
    "          # local strengths SST-->          \n",
    "          'g_pv_sst': -0.17 * brian2.nA,\n",
    "          'g_vip_sst': -0.1 * brian2.nA,\n",
    "          'g_e_sst_min': -0.09 * brian2.nA, # dopamine dependent min SST->E strength\n",
    "          'g_e_sst_max': -0.11 * brian2.nA, # dopamine dependent max SST->E strength\n",
    "          # local strengths VIP-->     \n",
    "          'g_sst_vip': -0.05 * brian2.nA,\n",
    "        # VTA strengths\n",
    "          'g_vta_da_I': -0.55 * brian2.nA,\n",
    "          'g_VTA_DA_ctx_E_scale': 0.047,\n",
    "          'g_VTA_I_ctx_E_scale': 0.02,\n",
    "          'c_VTA_DA_E1_init': 0.7,\n",
    "          'c_VTA_DA_E2_init': 1,\n",
    "\n",
    "\n",
    "    \n",
    "          # adaptation strengths\n",
    "          'g_adapt_e': -0.004 * brian2.nA,\n",
    "          'g_adapt_sst': -0.004 * brian2.nA,\n",
    "          'g_adapt_vip': -0.004 * brian2.nA,\n",
    "          # background currents\n",
    "          'I_background_e': 310 * brian2.pA,\n",
    "          'I_background_i': 300 * brian2.pA,\n",
    "          'I_background_dend': 30 * brian2.pA,\n",
    "          'I_background_da_vta': 350 * brian2.pA,\n",
    "          'I_background_i_vta': 250 * brian2.pA,\n",
    "    \n",
    "          # noise\n",
    "          'std_noise': 5 * brian2.pA,\n",
    "\n",
    "\n",
    "          # Long-range connectivity strengths\n",
    "          # projections from superficial layers to E cells\n",
    "          'mu_ee': 1.45,\n",
    "          # Long-range connectivity strengths\n",
    "          # projections from deep layers to I cells\n",
    "          'mu_ie': 2.24,\n",
    "          # Fraction of long-range superficial (E-->E) connections onto each population    \n",
    "          'lr_e_self_dend': 0.9,\n",
    "          'lr_e_cross_dend': 0.1,\n",
    "          # Fraction of long-range deep (E-->I) connections onto each population    \n",
    "          'lr_pv_e': 0.31,\n",
    "          'lr_sst_e_self': 0.22 ,\n",
    "          'lr_vip_e_self': 0.47,\n",
    "          # parameters for m current\n",
    "          'midpoint_m' : 0.85,#0.85\n",
    "          'slope_m' : 14,\n",
    "          'g_m' : -0.5  * brian2.nA,\n",
    "          # parameters for D1 occupancy\n",
    "          'midpoint_d1occ' : 1,\n",
    "          'slope_d1occ' : 2,\n",
    "          # parameters for DA modulation of NMDA\n",
    "          'midpoint_nmda_da' : 0.35,\n",
    "          'slope_nmda_da' : 10,\n",
    "          'g_nmda_da': 0.6,\n",
    "\n",
    "          # excitatory gradient parameters\n",
    "          'e_grad_min': 0.45,\n",
    "          # stimulus strength \n",
    "          'stim_strength': 0.1 * brian2.nA,\n",
    "    \n",
    "          # stimulus strength \n",
    "          'reward_strength': -0.2 * brian2.nA,\n",
    "\t\t  # squish connectivity matrix params\n",
    "          'b1': 0.3,\n",
    "\t\t  # AMPA/(AMPA+NMDA) fraction \n",
    "          'ampa_frac': 0.1,\n",
    "          'ampa_frac_pv': 0.2,\n",
    "          'dt': 0.5 * brian2.ms,\n",
    "          'trial_length': 13 * brian2.second,\n",
    "          'stim_on': 6 * brian2.second,\n",
    "          'stim_off': 6.4 * brian2.second,\n",
    "          'distract_on': 7 * brian2.second,\n",
    "          'distract_off': 7.4 * brian2.second,\n",
    "          'ping_on': 8 * brian2.second,\n",
    "          'ping_off': 8.4 * brian2.second,\n",
    "#           'reward_on': 8 * brian2.second,\n",
    "#           'reward_off': 9.9 * brian2.second,\n",
    "          # STD_\n",
    "          'learning_rate_up': 0.2,\n",
    "          'learning_rate_down': 0.2,\n",
    "          # dopamine release\n",
    "          'da_rel': 1.5}\n",
    "\n",
    "with open('large_scale_visualWM_DA_params.pck', 'wb') as f:\n",
    "    pickle.dump(PARAMS, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('large_scale_visualWM_DA_params.pck') as f:\n",
    "#     PARAMS_2 = pickle.load(f)\n",
    "\n",
    "\n",
    "# print(PARAMS_2['stim_strength'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in anatomical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_anatomy():\n",
    "    # Load in anatomical data file\n",
    "    subgraph_data = sio.loadmat('anatomical_data/beta_bin_hierarchy_subgraph.mat')\n",
    "    sln = subgraph_data['HierOrderedSLNsubgraph']\n",
    "    fln = subgraph_data['HierOrderedFLNsubgraph']\n",
    "    hierarchy = subgraph_data['hierarchy_vals_subgraph']\n",
    "\n",
    "\n",
    "    temp_list = subgraph_data['subgraph_hierarchical_order']\n",
    "    area_list_SLN = []\n",
    "    for row in temp_list:\n",
    "        v = '%s' % str(row[0][0])\n",
    "        area_list_SLN.append(v)\n",
    "\n",
    "    area_column_list  = ['from '+ mystring for mystring in area_list_SLN]\n",
    "    area_row_list  = ['to '+ mystring for mystring in area_list_SLN]\n",
    "\n",
    "    df_fln = pandas.DataFrame(fln , columns=area_column_list, index=area_row_list)\n",
    "\n",
    "    df_sln = pandas.DataFrame(sln , columns=area_column_list, index=area_row_list)\n",
    "\n",
    "    # load the receptor data\n",
    "    D1R_data = sio.loadmat('anatomical_data/D1R_lyon_regions.mat')\n",
    "\n",
    "    D1_density_raw = D1R_data['D1R_lyon_regions_40']\n",
    "\n",
    "    # load the spine count data\n",
    "    spine_data = sio.loadmat('anatomical_data/spine_count_lyon_regions.mat')\n",
    "\n",
    "    spine_count_raw = spine_data['spine_count_lyon_regions_40']\n",
    "\n",
    "    df_raw_anatomy = pandas.DataFrame(D1_density_raw, columns=['D1R'], index=area_list_SLN)\n",
    "    df_raw_anatomy.loc[:,'spines'] = spine_count_raw\n",
    "    df_raw_anatomy.loc[:,'hierarchy'] = hierarchy\n",
    "\n",
    "      \n",
    "    # Load in the list of areas that show persistent activity according to Leavitt et al\n",
    "    persistent_areas_experimental_mat = sio.loadmat('anatomical_data/persistent_areas_experimental.mat')\n",
    "    persistent_activity_areas_all = persistent_areas_experimental_mat['persistent_areas_data']\n",
    "    well_studied_areas = persistent_areas_experimental_mat['well_studied']\n",
    "    persistent_activity_areas = persistent_activity_areas_all*well_studied_areas\n",
    "    \n",
    "    \n",
    "    return (sln, fln, hierarchy, area_list_SLN,\n",
    "        df_fln, df_sln, D1_density_raw, spine_count_raw, df_raw_anatomy,persistent_activity_areas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_connectivity(parameters,spine_count_raw,fln,sln,d1_density_raw):\n",
    "\n",
    "    d1_occ = sigmoid_DA(parameters['da_rel'],parameters['midpoint_d1occ'],parameters['slope_d1occ'])\n",
    "\n",
    "    ######## Excitatory gradient ########\n",
    "    # scale spine count to lie within [0,1] range\n",
    "    min_spine_count = np.min(spine_count_raw)\n",
    "    spine_count_rescaled = spine_count_raw-min_spine_count\n",
    "    spine_grad = spine_count_rescaled/np.max(spine_count_rescaled)\n",
    "\n",
    "    # define the excitatory gradient to lie according to the spine count \n",
    "    e_grad_scaling_factor = 1 - parameters['e_grad_min'] \n",
    "    e_grad = parameters['e_grad_min'] + e_grad_scaling_factor*spine_grad\n",
    "\n",
    "    ######## Local connectivity ########\n",
    "    # set up the local connectivity matrix\n",
    "    J =  np.array([[parameters['g_e_self'] , parameters['g_e_cross'], 0, 0, parameters['g_pv_e'], parameters['g_sst_e_self'], parameters['g_sst_e_cross'],parameters['g_vip_e'],0],\n",
    "                   [parameters['g_e_cross'] , parameters['g_e_self'],  0, 0, parameters['g_pv_e'], parameters['g_sst_e_cross'], parameters['g_sst_e_self'], 0, parameters['g_vip_e']],\n",
    "                   [0,0,0,0,0,0,0,0,0],\n",
    "                   [0,0,0,0,0,0,0,0,0],\n",
    "                  [parameters['g_e_pv_min'],parameters['g_e_pv_min'],0,0,parameters['g_pv_self'], 0, 0,0,0],\n",
    "                  [0,0,0,0,parameters['g_pv_sst'], 0, 0,parameters['g_vip_sst'],0],\n",
    "                  [0,0,0,0,parameters['g_pv_sst'], 0, 0, 0,parameters['g_vip_sst']],\n",
    "                  [0,0,0,0,0,parameters['g_sst_vip'],0,0,0],\n",
    "                  [0,0,0,0,0,0,parameters['g_sst_vip'],0,0]\n",
    "                  ]).T * brian2.amp\n",
    "\n",
    "\n",
    "    pops = ['E1soma','E2soma','E1dend','E2dend','PV','SST1','SST2','VIP1','VIP2']\n",
    "    pops_column_list  = ['from '+ mystring for mystring in pops]\n",
    "    pops_row_list  = ['to '+ mystring for mystring in pops]\n",
    "\n",
    "    J_display = J*(1/brian2.pA)\n",
    "    df_J = pandas.DataFrame(J_display, columns=pops_column_list, index=pops_row_list)\n",
    "    df_J\n",
    "\n",
    "    ######### numbers of areas, populations ##########\n",
    "\n",
    "    num_pops  = J.shape[0]\n",
    "    num_e_pops = 2\n",
    "    num_areas = fln.shape[0]\n",
    "\n",
    "    ######### adaptation ###########\n",
    "    g_adapt = np.array([parameters['g_adapt_e'],parameters['g_adapt_e'],0,0,0,\n",
    "                        parameters['g_adapt_sst'],parameters['g_adapt_sst'],parameters['g_adapt_vip']\n",
    "                        ,parameters['g_adapt_vip']])* brian2.amp \n",
    "\n",
    "    \n",
    "    g_m = np.array([parameters['g_m'],parameters['g_m'],0,0,0,0,0,0,0])* brian2.amp \n",
    "    \n",
    "    ######### AMPA/(AMPA+NMDA) fraction ##########\n",
    "\n",
    "    ampa_frac = np.array([parameters['ampa_frac'],parameters['ampa_frac'],parameters['ampa_frac'],parameters['ampa_frac']\n",
    "                          ,parameters['ampa_frac_pv'],parameters['ampa_frac'],parameters['ampa_frac']\n",
    "                          ,parameters['ampa_frac'],parameters['ampa_frac']])\n",
    "    nmda_frac = 1 - ampa_frac\n",
    "\n",
    "    J_nmda = J*((J>0).astype(np.int))\n",
    "    J_ampa = J*((J>0).astype(np.int))\n",
    "    J_gaba = J*((J<0).astype(np.int))\n",
    "\n",
    "    J_gaba_dend =  np.array([[0,0,0,0,0,parameters['g_e_sst_min'],0,0,0],\n",
    "                   [0,0,0,0,0,0,parameters['g_e_sst_min'],0,0]]) * brian2.amp \n",
    "\n",
    "    ####### LONG-RANGE CONNECTIONS ########\n",
    "    # Compress FLN\n",
    "    fln_squish = np.power(fln,parameters['b1'])\n",
    "    fln_rowtotal = np.sum(fln_squish,axis=1)\n",
    "    fln_rowtotal_mat = np.matlib.repmat(fln_rowtotal, num_areas,1).T\n",
    "    fln_squishnorm = fln_squish/fln_rowtotal_mat\n",
    "\n",
    "    # Isolate long-range connections from superficial layers\n",
    "    W_superficial = fln_squishnorm*sln\n",
    "    # Isolate long-range connections from deep layers\n",
    "    W_deep = fln_squishnorm*(1-sln)\n",
    "\n",
    "\n",
    "    # This matrix splits the long-range current onto each local population of cells\n",
    "    lr_targets = np.array([[0, 0,parameters['lr_e_self_dend'],parameters['lr_e_cross_dend']\n",
    "                                 ,parameters['lr_pv_e'],parameters['lr_sst_e_self'],0,parameters['lr_vip_e_self'],0],\n",
    "                                [0, 0, parameters['lr_e_cross_dend'], parameters['lr_e_self_dend']\n",
    "                                 ,parameters['lr_pv_e'],0,parameters['lr_sst_e_self'],0,parameters['lr_vip_e_self']]]).T * brian2.nA\n",
    "\n",
    "    # This matrix splits the long-range current onto each local population of cells - reflecting greater proportion of CR cells in FEF (Pouget et al., 2009)\n",
    "    lr_targets_FEF = np.array([[0, 0,parameters['lr_e_self_dend'],parameters['lr_e_cross_dend']\n",
    "                                 ,0.2,0.1,0,0.7,0],\n",
    "                                [0, 0, parameters['lr_e_cross_dend'], parameters['lr_e_self_dend']\n",
    "                                 ,0.2,0,0.1,0,0.7]]).T * brian2.nA\n",
    "\n",
    "    ##### Dopamine modulation #####\n",
    "    # scale_receptors to lie within [0,1] range\n",
    "    min_d1R = np.min(d1_density_raw)\n",
    "    d1R_rescaled = np.squeeze(d1_density_raw)-min_d1R\n",
    "    d1_grad = d1R_rescaled/np.max(d1R_rescaled)\n",
    "\n",
    "    # strength of excitatory currents through NMDA receptors increases with dopamine (Seamans et al., PNAS, 2001)\n",
    "    # To remove effect of dopamine on NMDA, while keeping other dopamine effects, set d1_occ here = 0\n",
    "    nmda_da_grad = 1 + parameters['g_nmda_da']*sigmoid_DA(d1_occ*np.expand_dims(d1_grad,axis=1),parameters['midpoint_nmda_da'],parameters['slope_nmda_da'])\n",
    "\n",
    "    # PV-->soma strength decreases with dopamine (Gao et al., J Neurosci, 2003)\n",
    "    # To remove effect of dopamine on PV-->E connections, while keeping other dopamine effects, set d1_occ here = 0\n",
    "    e_pv_da_grad = (parameters['g_e_pv_max'] + d1_occ*d1_grad*(parameters['g_e_pv_min'] - parameters['g_e_pv_max']))/parameters['g_e_pv_min']\n",
    "    e_pv_da_mat = np.concatenate((np.expand_dims(e_pv_da_grad,axis=1),np.expand_dims(e_pv_da_grad,axis=1),np.ones((num_areas,num_pops-num_e_pops))),axis=1)\n",
    "\n",
    "    # SST-->dendrite strength increases with dopamine (Gao et al., J Neurosci, 2003)\n",
    "    # To remove effect of dopamine on PV-->E connections, while keeping other dopamine effects, set d1_occ here = 0\n",
    "    e_sst_da_grad = (parameters['g_e_sst_min'] + d1_occ*d1_grad*(parameters['g_e_sst_max'] - parameters['g_e_sst_min']))/parameters['g_e_sst_min']\n",
    "    e_sst_da_mat = np.concatenate((np.expand_dims(e_sst_da_grad,axis=1),np.expand_dims(e_sst_da_grad,axis=1)),axis=1)\n",
    "\n",
    "    # High levels of D1 receptor stimulation engage an outward M-channel, reducing excitability (Arnsten et al., Neurobio. Stress., 2019)\n",
    "    # To remove effect of dopamine on the M-channel, while keeping other dopamine effects, set d1_occ here = 0\n",
    "    m_da_grad = sigmoid_DA(d1_occ*d1_grad,parameters['midpoint_m'],parameters['slope_m']).reshape(num_areas,1)\n",
    "\n",
    "    return(pops, num_pops, num_e_pops, num_areas, e_grad, g_adapt, ampa_frac, nmda_frac, J_nmda, J_ampa, \n",
    "          J_gaba, J_gaba_dend, W_superficial, W_deep, lr_targets, nmda_da_grad, e_pv_da_mat, e_sst_da_mat, m_da_grad,g_m,lr_targets_FEF,d1_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_vta_connectivity(parameters,c_VTA_DA_E1_now,c_VTA_DA_E2_now):\n",
    "\n",
    "    # set VTA parameters\n",
    "    I_background_vta = np.array([parameters['I_background_da_vta'],parameters['I_background_i_vta']])  * brian2.nA\n",
    "    # # # Long-range strengths to VTA\n",
    "    # g_VTA_DA_ctx_E2 = 0.03 \n",
    "    # g_VTA_DA_ctx_E1 = 0.005    \n",
    "    # # g_VTA_DA_ctx_E0 = 0.03\n",
    "    # # g_VTA_E_ctx  = 0.00   \n",
    "    # g_VTA_I_ctx_E2  = 0.01   \n",
    "    # g_VTA_I_ctx_E1  = 0.002  \n",
    "\n",
    "    # scale the cortex to vta synapses\n",
    "    g_VTA_DA_ctx_E1 = parameters['g_VTA_DA_ctx_E_scale']*c_VTA_DA_E1_now\n",
    "    g_VTA_DA_ctx_E2 = parameters['g_VTA_DA_ctx_E_scale']*c_VTA_DA_E2_now\n",
    "    g_VTA_I_ctx_E1 = parameters['g_VTA_I_ctx_E_scale']*c_VTA_DA_E1_now\n",
    "    g_VTA_I_ctx_E2 = parameters['g_VTA_I_ctx_E_scale']*c_VTA_DA_E2_now\n",
    "\n",
    "\n",
    "    W_vta_ctx = np.array([[g_VTA_DA_ctx_E1,g_VTA_I_ctx_E1],\n",
    "                          [g_VTA_DA_ctx_E2,g_VTA_I_ctx_E2]])\n",
    "\n",
    "    J_vta_local = np.array([[0,parameters['g_vta_da_I']],\n",
    "                             [0, 0 ]]) *brian2.nA\n",
    "\n",
    "    num_vta_pops = 2\n",
    "    pops_vta = ['DA','I']\n",
    "    return(W_vta_ctx,J_vta_local,num_vta_pops,pops_vta,I_background_vta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_variables(PARAMS,num_areas,num_pops,num_e_pops,area_list_SLN,stim_order):\n",
    "\n",
    "    # Initialise\n",
    "    num_iterations = int(PARAMS['trial_length']/PARAMS['dt'])\n",
    "\n",
    "    # Choose initial values for rates and synapse variables\n",
    "    R0 = np.matlib.repmat(np.array([PARAMS['r_0_e'],PARAMS['r_0_e'],0,0,PARAMS['r_0_e'],PARAMS['r_0_e'],PARAMS['r_0_e'],PARAMS['r_0_e'],PARAMS['r_0_e']]), num_areas, 1) * brian2.Hz\n",
    "    R = np.zeros((num_iterations,num_areas,num_pops)) * brian2.Hz\n",
    "    R[0,:,:] = R0\n",
    "\n",
    "    s_nmda = np.zeros((num_iterations,num_areas,num_pops))\n",
    "    s_ampa = np.zeros((num_iterations,num_areas,num_pops))\n",
    "    s_gaba = np.zeros((num_iterations,num_areas,num_pops))\n",
    "    s_gaba_dend = np.zeros((num_iterations,num_areas,num_pops))\n",
    "    s_adapt = np.zeros((num_iterations,num_areas,num_pops))\n",
    "    s_nmda_stp = np.zeros((num_iterations,num_areas,num_pops))\n",
    "    s_ampa_stp = np.zeros((num_iterations,num_areas,num_pops))\n",
    "    x = np.zeros((num_iterations,num_areas,num_e_pops))\n",
    "    x[0,:,:] = PARAMS['x0']*np.ones((num_areas,num_e_pops))\n",
    "    u = np.zeros((num_iterations,num_areas,num_e_pops))\n",
    "    u[0,:,:] = PARAMS['u0']*np.ones((num_areas,num_e_pops))\n",
    "\n",
    "    \n",
    "    # # Preassign external inputs\n",
    "    I_ext    = np.zeros((num_iterations,num_areas,num_pops)) * brian2.amp\n",
    "\n",
    "    \n",
    "    if stim_order == 1:\n",
    "        # Let's apply external stimulation to V1 populations E1 & E2\n",
    "        I_ext[int(PARAMS['stim_on']/PARAMS['dt']):int(PARAMS['stim_off']/PARAMS['dt']),area_list_SLN.index('V1'),pops.index('E1dend')] = PARAMS['stim_strength']\n",
    "        I_ext[int(PARAMS['distract_on']/PARAMS['dt']):int(PARAMS['distract_off']/PARAMS['dt']),area_list_SLN.index('V1'),pops.index('E2dend')] = PARAMS['stim_strength']\n",
    "    elif stim_order == 2:\n",
    "        # Let's apply external stimulation to V1 populations E1 & E2\n",
    "        I_ext[int(PARAMS['stim_on']/PARAMS['dt']):int(PARAMS['stim_off']/PARAMS['dt']),area_list_SLN.index('V1'),pops.index('E1dend')] = PARAMS['stim_strength']\n",
    "        I_ext[int(PARAMS['distract_on']/PARAMS['dt']):int(PARAMS['distract_off']/PARAMS['dt']),area_list_SLN.index('V1'),pops.index('E2dend')] = PARAMS['stim_strength']\n",
    "    \n",
    "    I_ext[int(PARAMS['ping_on']/PARAMS['dt']):int(PARAMS['ping_off']/PARAMS['dt']),area_list_SLN.index('V1'),[pops.index('E1dend'),pops.index('E2dend')]] = PARAMS['stim_strength']\n",
    "\n",
    "#     reward    = np.zeros((num_iterations,num_vta_pops)) * brian2.amp\n",
    "    \n",
    "#     # Let's apply the positive reward as inhibition to VTA GABA cells (see Soden et al., Nat Neurosci, 2020)\n",
    "#     reward[int(PARAMS['reward_on']/PARAMS['dt']):int(PARAMS['reward_off']/PARAMS['dt']),pops_vta.index('I')] = PARAMS['reward_strength']\n",
    "\n",
    "# #     # Let's apply the negative reward as inhibition to VTA DA cells (\n",
    "#     reward[int(PARAMS['reward_on']/PARAMS['dt']):int(PARAMS['reward_off']/PARAMS['dt']),pops_vta.index('DA')] = PARAMS['reward_strength']\n",
    "\n",
    "    \n",
    "    # Create matrices in which we can store the currents\n",
    "    I_lr_nmda    =  np.zeros((num_iterations,num_areas,num_pops)) * brian2.pA\n",
    "    I_lr_ampa    =  np.zeros((num_iterations,num_areas,num_pops)) * brian2.pA\n",
    "    I_local_nmda =  np.zeros((num_iterations,num_areas,num_pops)) * brian2.pA\n",
    "    I_local_ampa =  np.zeros((num_iterations,num_areas,num_pops)) * brian2.pA\n",
    "    I_local_gaba =  np.zeros((num_iterations,num_areas,num_pops)) * brian2.pA\n",
    "    I_soma_dend  =  np.zeros((num_iterations,num_areas,num_pops)) * brian2.pA\n",
    "    I_total      =  np.zeros((num_iterations,num_areas,num_pops)) * brian2.pA\n",
    "    I_exc_dend   = np.zeros((num_iterations,num_areas,num_e_pops)) * brian2.pA\n",
    "    I_inh_dend   = np.zeros((num_iterations,num_areas,num_e_pops)) * brian2.pA\n",
    "    I_local_gaba_dend =  np.zeros((num_iterations,num_areas,num_e_pops)) * brian2.pA\n",
    "    I_adapt = np.zeros((num_iterations,num_areas,num_pops)) * brian2.pA\n",
    "\n",
    "    # preassign variables VTA\n",
    "    I_lr_nmda_vta = np.zeros((num_iterations,num_vta_pops)) * brian2.pA   \n",
    "    I_lr_ampa_vta = np.zeros((num_iterations,num_vta_pops)) * brian2.pA\n",
    "    I_local_nmda_vta = np.zeros((num_iterations,num_vta_pops)) * brian2.pA   \n",
    "    I_local_ampa_vta = np.zeros((num_iterations,num_vta_pops)) * brian2.pA   \n",
    "    I_local_gaba_vta = np.zeros((num_iterations,num_vta_pops)) * brian2.pA    \n",
    "    total_vta_input  = np.zeros((num_iterations,num_vta_pops)) * brian2.pA\n",
    "    R_vta = np.zeros((num_iterations,num_vta_pops)) * brian2.Hz\n",
    "    s_nmda_vta  = np.zeros((num_iterations,num_vta_pops))\n",
    "    s_ampa_vta  = np.zeros((num_iterations,num_vta_pops))\n",
    "    s_gaba_vta  = np.zeros((num_iterations,num_vta_pops))\n",
    "    dyn_da_rel_ctx  = np.zeros((num_iterations))\n",
    "    dyn_da_rel_vta  = np.zeros((num_iterations))\n",
    "\n",
    "\n",
    "    \n",
    "    # Define background inputs\n",
    "    I_0 = np.zeros((num_areas,num_pops)) * brian2.pA\n",
    "    I_0[:,[pops.index('E1soma'),pops.index('E2soma')]] = PARAMS['I_background_e']\n",
    "    I_0[:,[pops.index('E1dend'),pops.index('E2dend')]] = PARAMS['I_background_dend']\n",
    "    I_0[:,[pops.index('PV'),pops.index('SST1'),pops.index('SST2'),pops.index('VIP1'),pops.index('VIP2')]] = PARAMS['I_background_i']\n",
    "\n",
    "    # Let's set up the noise. We will model the noise as an Ornstein-Uhlenbeck process.\n",
    "    # Gaussian noise. mean 0, std 1. Dims: timesteps, local populations, areas\n",
    "    eta = np.random.normal(loc=0.0, scale=1.0, size=(num_iterations,num_areas,num_pops))\n",
    "\n",
    "    # prepare the right hand side of the above equation\n",
    "    noise_rhs = eta*((np.sqrt(PARAMS['tau_ampa']*np.power(PARAMS['std_noise'],2))*np.sqrt(PARAMS['dt']))/PARAMS['tau_ampa'])\n",
    "    noise_rhs[:,:,2:4] = 0 # remove noise from dendrites\n",
    "    I_noise = np.zeros((num_areas , num_pops )) *brian2.pA\n",
    "\n",
    "    return(num_iterations,R,s_nmda,s_ampa,s_gaba,s_gaba_dend,s_adapt\n",
    "           ,I_ext,I_lr_nmda,I_lr_ampa,I_local_nmda,I_local_ampa,I_local_gaba\n",
    "           ,I_soma_dend,I_total,I_exc_dend,I_inh_dend,I_local_gaba_dend,I_adapt\n",
    "           ,I_0,I_noise,noise_rhs,I_lr_nmda_vta,I_lr_ampa_vta,I_local_nmda_vta\n",
    "           ,I_local_ampa_vta,I_local_gaba_vta,total_vta_input,R_vta,s_nmda_vta\n",
    "           ,s_ampa_vta,s_gaba_vta,dyn_da_rel_ctx,dyn_da_rel_vta,s_nmda_stp,s_ampa_stp,x,u)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " def large_scale_da_model(pops, num_pops, num_e_pops, num_areas, e_grad, g_adapt, ampa_frac, nmda_frac\n",
    "                          , J_nmda, J_ampa, J_gaba, J_gaba_dend, W_superficial, W_deep, lr_targets\n",
    "                          , nmda_da_grad, e_pv_da_mat, e_sst_da_mat, m_da_grad,num_iterations,R,s_nmda\n",
    "                          ,s_ampa,s_gaba,s_gaba_dend,s_adapt\n",
    "                          ,I_ext,I_lr_nmda,I_lr_ampa,I_local_nmda,I_local_ampa,I_local_gaba\n",
    "                          ,I_soma_dend,I_total,I_exc_dend,I_inh_dend,I_local_gaba_dend,I_adapt\n",
    "                          ,I_0,I_noise,noise_rhs,parameters,lr_targets_FEF,I_lr_nmda_vta,I_lr_ampa_vta\n",
    "                          ,I_local_nmda_vta,I_local_ampa_vta,I_local_gaba_vta,total_vta_input,R_vta\n",
    "                          ,s_nmda_vta,s_ampa_vta,s_gaba_vta,dyn_da_rel_ctx,dyn_da_rel_vta,I_background_vta,W_vta_ctx\n",
    "                          ,J_vta_local,d1_grad,s_nmda_stp,s_ampa_stp,x,u):\n",
    "    for i_t in range(1,num_iterations):\n",
    "            \n",
    "        # translate DA release to D1R occupancy \n",
    "        d1_occ = sigmoid_DA(dyn_da_rel_ctx[i_t-1],parameters['midpoint_d1occ'],parameters['slope_d1occ'])\n",
    "\n",
    "        # strength of excitatory currents through NMDA receptors increases with dopamine (Seamans et al., PNAS, 2001)\n",
    "        # To remove effect of dopamine on NMDA, while keeping other dopamine effects, set d1_occ here = 0\n",
    "        nmda_da_grad = 1 + parameters['g_nmda_da']*sigmoid_DA(d1_occ*np.expand_dims(d1_grad,axis=1),parameters['midpoint_nmda_da'],parameters['slope_nmda_da'])\n",
    "\n",
    "        # PV-->soma strength decreases with dopamine (Gao et al., J Neurosci, 2003)\n",
    "        # To remove effect of dopamine on PV-->E connections, while keeping other dopamine effects, set d1_occ here = 0\n",
    "        e_pv_da_grad = (parameters['g_e_pv_max'] + d1_occ*d1_grad*(parameters['g_e_pv_min'] - parameters['g_e_pv_max']))/parameters['g_e_pv_min']\n",
    "        e_pv_da_mat = np.concatenate((np.expand_dims(e_pv_da_grad,axis=1),np.expand_dims(e_pv_da_grad,axis=1),np.ones((num_areas,num_pops-num_e_pops))),axis=1)\n",
    "\n",
    "        # SST-->dendrite strength increases with dopamine (Gao et al., J Neurosci, 2003)\n",
    "        # To remove effect of dopamine on PV-->E connections, while keeping other dopamine effects, set d1_occ here = 0\n",
    "        e_sst_da_grad = (parameters['g_e_sst_min'] + d1_occ*d1_grad*(parameters['g_e_sst_max'] - parameters['g_e_sst_min']))/parameters['g_e_sst_min']\n",
    "        e_sst_da_mat = np.concatenate((np.expand_dims(e_sst_da_grad,axis=1),np.expand_dims(e_sst_da_grad,axis=1)),axis=1)\n",
    "\n",
    "        # High levels of D1 receptor stimulation engage an outward M-channel, reducing excitability (Arnsten et al., Neurobio. Stress., 2019)\n",
    "        # To remove effect of dopamine on the M-channel, while keeping other dopamine effects, set d1_occ here = 0\n",
    "        m_da_grad = sigmoid_DA(d1_occ*d1_grad,parameters['midpoint_m'],parameters['slope_m']).reshape(num_areas,1)\n",
    "\n",
    "        # update noise - dims = num local pops x num areas\n",
    "        I_noise = I_noise + -I_noise*(parameters['dt']/parameters['tau_ampa']) + noise_rhs[i_t-1,:,:]\n",
    "\n",
    "        # Long range NMDA to E populations \n",
    "        I_lr_nmda[i_t-1,:,:4]   = ((e_grad*parameters['mu_ee']*nmda_da_grad)*W_superficial).dot(s_nmda[i_t-1,:,:2]).dot(nmda_frac[:4]*lr_targets[:4,:].T)\n",
    "        # Long range NMDA to I populations \n",
    "        I_lr_nmda[i_t-1,:,4:]   = parameters['mu_ie']*e_grad*nmda_da_grad*(W_deep.dot(s_nmda[i_t-1,:,:2])).dot(nmda_frac[4:]*lr_targets[4:,:].T)\n",
    "        # Long range NMDA to I populations in FEF\n",
    "        I_lr_nmda[i_t-1,[area_list_SLN.index('8m'),area_list_SLN.index('8l')],4:]   = parameters['mu_ie']*e_grad[[area_list_SLN.index('8m'),area_list_SLN.index('8l')]]*nmda_da_grad[[area_list_SLN.index('8m'),area_list_SLN.index('8l')]]*(W_deep[[area_list_SLN.index('8m'),area_list_SLN.index('8l')],:].dot(s_nmda[i_t-1,:,:2])).dot(nmda_frac[4:]*lr_targets_FEF[4:,:].T)\n",
    "        \n",
    "        \n",
    "        # Long range AMPA to E populations \n",
    "        I_lr_ampa[i_t-1,:,:4]   = ((e_grad*parameters['mu_ee'])*W_superficial).dot(s_ampa[i_t-1,:,:2]).dot(ampa_frac[:4]*lr_targets[:4,:].T)\n",
    "        # Long range AMPA to I populations \n",
    "        I_lr_ampa[i_t-1,:,4:]   = parameters['mu_ie']*e_grad*(W_deep.dot(s_ampa[i_t-1,:,:2])).dot(ampa_frac[4:]*lr_targets[4:,:].T)\n",
    "        # Long range AMPA to I populations in FEF\n",
    "        I_lr_ampa[i_t-1,[area_list_SLN.index('8m'),area_list_SLN.index('8l')],4:]   = parameters['mu_ie']*e_grad[[area_list_SLN.index('8m'),area_list_SLN.index('8l')]]*(W_deep[[area_list_SLN.index('8m'),area_list_SLN.index('8l')],:].dot(s_ampa[i_t-1,:,:2])).dot(ampa_frac[4:]*lr_targets_FEF[4:,:].T)\n",
    "        \n",
    "        \n",
    "        # local NMDA\n",
    "        I_local_nmda[i_t-1,:,:] = nmda_frac*nmda_da_grad*e_grad*J_nmda.dot(s_nmda[i_t-1,:,:].T).T\n",
    "\n",
    "        # local AMPA\n",
    "        I_local_ampa[i_t-1,:,:] = ampa_frac*e_grad*J_ampa.dot(s_ampa[i_t-1,:,:].T).T\n",
    "\n",
    "        # sum up all the local GABA current onto E and I cell somas\n",
    "        I_local_gaba[i_t-1,:,:] = e_pv_da_mat*(J_gaba.dot(s_gaba[i_t-1,:,:].T).T)\n",
    "\n",
    "        # sum up all the local GABA current onto dendrites\n",
    "        I_local_gaba_dend[i_t-1,:,:] = e_sst_da_mat*(J_gaba_dend.dot(s_gaba_dend[i_t-1,:,:].T).T)\n",
    "\n",
    "        # calculate the dendrite-to-soma current\n",
    "        I_exc_dend[i_t-1,:,:] = I_local_nmda[i_t-1,:,2:4] + I_lr_nmda[i_t-1,:,2:4] + I_local_ampa[i_t-1,:,2:4] + I_lr_ampa[i_t-1,:,2:4] +I_0[:,2:4] + I_ext[i_t-1,:,2:4] + I_noise[:,2:4]\n",
    "\n",
    "        I_inh_dend[i_t-1,:,:] = I_local_gaba_dend[i_t-1,:,:] \n",
    "\n",
    "        I_soma_dend[i_t-1,:,:2]  = dendrite_input_output(I_exc_dend[i_t-1,:,:],I_inh_dend[i_t-1,:,:],parameters)\n",
    "\n",
    "        # adaptation current\n",
    "#         I_adapt[i_t-1,:,:] = (g_adapt+g_m*m_da_grad)*s_adapt[i_t-1,:,:]\n",
    "        I_adapt[i_t-1,:,:] = g_adapt*s_adapt[i_t-1,:,:]\n",
    "\n",
    "        # Define total input current as sum of local NMDA & GABA inputs, with background and external currents, \n",
    "        # noise and long-range NMDA inputs, and an adaptation current\n",
    "        I_total[i_t-1,:,:] = I_local_nmda[i_t-1,:,:] + I_local_ampa[i_t-1,:,:] +  I_local_gaba[i_t-1,:,:] + I_0 + I_ext[i_t-1,:,:] + I_noise + I_lr_nmda[i_t-1,:,:] + I_lr_ampa[i_t-1,:,:] + I_soma_dend[i_t-1,:,:] + I_adapt[i_t-1,:,:] \n",
    "\n",
    "        # calculate current inputs to VTA\n",
    "        # inputs to DA\n",
    "        I_lr_nmda_vta[i_t-1,0]   = np.sum([s_nmda[i_t-1,:,:2].dot(W_vta_ctx[:,0])],axis=1) *brian2.nA\n",
    "        I_lr_ampa_vta[i_t-1,0]   = np.sum([s_ampa[i_t-1,:,:2].dot(W_vta_ctx[:,0])],axis=1) *brian2.nA\n",
    "        # inputs to inhibitory neurons in VTA\n",
    "        I_lr_nmda_vta[i_t-1,1]   = np.sum([s_nmda_stp[i_t-1,:,:2].dot(W_vta_ctx[:,1])],axis=1) *brian2.nA\n",
    "        I_lr_ampa_vta[i_t-1,1]   = np.sum([s_ampa_stp[i_t-1,:,:2].dot(W_vta_ctx[:,1])],axis=1) *brian2.nA\n",
    "       \n",
    "        I_local_gaba_vta[i_t-1,:]      = J_vta_local.dot(s_gaba_vta[i_t-1,:])\n",
    "\n",
    "\n",
    "        total_vta_input[i_t-1,:] =    I_background_vta + I_lr_nmda_vta[i_t-1,:] + I_lr_ampa_vta[i_t-1,:] + I_local_nmda_vta[i_t-1,:] + I_local_ampa_vta[i_t-1,:] + I_local_gaba_vta[i_t-1,:]\n",
    "\n",
    "        \n",
    "        # Update the firing rates of the two excitatory populations.\n",
    "        R[i_t,:,:2] = R[i_t-1,:,:2] + parameters['dt']*current_to_frequency(I_total[i_t-1,:,:2],'E',parameters)/parameters['tau_ampa'] -parameters['dt']*R[i_t-1,:,:2]/parameters['tau_ampa']\n",
    "\n",
    "        # Update the firing rates of the PV population. \n",
    "        R[i_t,:,4] =  R[i_t-1,:,4] + parameters['dt']*current_to_frequency(I_total[i_t-1,:,4],'PV',parameters)/parameters['tau_ampa'] -parameters['dt']*R[i_t-1,:,4]/parameters['tau_ampa']\n",
    "\n",
    "        # Update the firing rates of the SST populations. \n",
    "        R[i_t,:,5:7] =  R[i_t-1,:,5:7] + parameters['dt']*current_to_frequency(I_total[i_t-1,:,5:7],'SST',parameters)/parameters['tau_ampa'] -parameters['dt']*R[i_t-1,:,5:7]/parameters['tau_ampa']\n",
    "\n",
    "        # Update the firing rates of the VIP populations. \n",
    "        R[i_t,:,7:] =  R[i_t-1,:,7:] +  parameters['dt']*current_to_frequency(I_total[i_t-1,:,7:],'VIP',parameters)/parameters['tau_ampa'] -parameters['dt']*R[i_t-1,:,7:]/parameters['tau_ampa']\n",
    "\n",
    "        # Update the firing rates of the DA and excitatory populations.\n",
    "        R_vta[i_t,0] = R_vta[i_t-1,0] + parameters['dt']*current_to_frequency(total_vta_input[i_t-1,0],'E',parameters)/parameters['tau_ampa'] -parameters['dt']*R_vta[i_t-1,0]/parameters['tau_ampa']\n",
    "\n",
    "        # Update the firing rates of the inhibitory population.\n",
    "        R_vta[i_t,1] = R_vta[i_t-1,1] + parameters['dt']*current_to_frequency(total_vta_input[i_t-1,1],'PV',parameters)/parameters['tau_ampa'] -parameters['dt']*R_vta[i_t-1,1]/parameters['tau_ampa']\n",
    "        \n",
    "        # Update the NMDA synapses\n",
    "        s_nmda[i_t,:,:2] = s_nmda[i_t-1,:,:2] + parameters['dt']*NMDA_deriv(s_nmda[i_t-1,:,:2],R[i_t,:,:2],parameters)\n",
    "\n",
    "        # Update the AMPA synapses\n",
    "        s_ampa[i_t,:,:2] = s_ampa[i_t-1,:,:2] + parameters['dt']*AMPA_deriv(s_ampa[i_t-1,:,:2],R[i_t,:,:2],parameters)\n",
    "\n",
    "        # Update the facilitation variable\n",
    "        u[i_t,:,:] = u[i_t-1,:,:] + parameters['dt']*STF_deriv(R[i_t,:,:2],u[i_t-1,:,:],parameters)\n",
    "\n",
    "        # Update the depression variable\n",
    "        x[i_t,:,:] = x[i_t-1,:,:] + parameters['dt']*STD_deriv(R[i_t,:,:2],x[i_t-1,:,:],u[i_t-1,:,:],parameters)\n",
    "\n",
    "        # Update the NMDA synapses\n",
    "        s_nmda_stp[i_t,:,:2] = s_nmda_stp[i_t-1,:,:2] + parameters['dt']*NMDA_deriv_STP(s_nmda_stp[i_t-1,:,:2],R[i_t,:,:2],parameters,u[i_t,:,:])\n",
    "\n",
    "        # Update the AMPA synapses\n",
    "        s_ampa_stp[i_t,:,:2] = s_ampa_stp[i_t-1,:,:2] + parameters['dt']*AMPA_deriv_STP(s_ampa_stp[i_t-1,:,:2],R[i_t,:,:2],parameters,u[i_t,:,:])\n",
    "        \n",
    "        # Update the GABA synapses onto the somata\n",
    "        s_gaba[i_t,:,4:] = s_gaba[i_t-1,:,4:] + parameters['dt']*GABA_deriv(s_gaba[i_t-1,:,4:],R[i_t,:,4:],parameters,'soma')\n",
    "\n",
    "        # Update the GABA synapses onto the dendrites\n",
    "        s_gaba_dend[i_t,:,4:] = s_gaba_dend[i_t-1,:,4:] + parameters['dt']*GABA_deriv(s_gaba_dend[i_t-1,:,4:],R[i_t,:,4:],parameters,'dendrite')\n",
    "\n",
    "        # Update the adaptation variable\n",
    "        s_adapt[i_t,:,:] = s_adapt[i_t-1,:,:] + parameters['dt']*adaptation_deriv(s_adapt[i_t-1,:,:],R[i_t,:,:],parameters)\n",
    "\n",
    "#         # Update the NMDA synapses\n",
    "#         s_nmda_vta[i_t,1:3] = s_nmda_vta[i_t-1,1:3] + parameters['dt']*NMDA_deriv(s_nmda_vta[i_t-1,1:3],R_vta[i_t,1:3],parameters)\n",
    "\n",
    "#         # Update the AMPA synapses\n",
    "#         s_ampa_vta[i_t,1:3] = s_ampa_vta[i_t-1,1:3] + parameters['dt']*AMPA_deriv(s_ampa_vta[i_t-1,1:3],R_vta[i_t,1:3],parameters)\n",
    "\n",
    "        # Update the GABA synapses onto the somata\n",
    "        s_gaba_vta[i_t,1] = s_gaba_vta[i_t-1,1] + parameters['dt']*GABA_deriv(s_gaba_vta[i_t-1,1],R_vta[i_t,1],parameters,'soma')\n",
    "\n",
    "        # release dopamine based on the firing rate of dopamine neurons\n",
    "        dyn_da_rel_ctx[i_t] = dyn_da_rel_ctx[i_t-1] + parameters['dt']*DAconc_deriv(dyn_da_rel_ctx[i_t-1],R_vta[i_t,0],parameters,'cortex')\n",
    "        \n",
    "        # release dopamine based on the firing rate of dopamine neurons\n",
    "        dyn_da_rel_vta[i_t] = dyn_da_rel_vta[i_t-1] + parameters['dt']*DAconc_deriv(dyn_da_rel_vta[i_t-1],R_vta[i_t,0],parameters,'vta')\n",
    "        \n",
    "        \n",
    "        \n",
    "    return(R,dyn_da_rel_ctx,dyn_da_rel_vta,x,u,R_vta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement reward based learning at the E-->DA synapses in the VTA according to the simplified Soltani & Wang rule\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Update E-->DA & I weights in VTA as follows:\n",
    "$$ g_{j,i}(t+1) = g_{D0}c_{i}(t+1)$$\n",
    "\n",
    "where $i \\epsilon {E1, E2}$ and $j \\epsilon {DA,I}$\n",
    "\n",
    "If E1 is selected & rewarded\n",
    "$$c(t+1) = c(t) + \\alpha(1 - c(t)) $$\n",
    "\n",
    "If E1 is selected & not rewarded\n",
    "$$c(t+1) = c(t) - \\alpha(c(t)) $$\n",
    "\n",
    "E1 is chosen if \n",
    "$$\\sum_{i \\epsilon FPN} \\frac{R_{E1,[i]}}{n} > \\sum_{i \\epsilon FPN} \\frac{R_{E2,[i]}}{n} $$\n",
    "\n",
    "where n is the number of areas in the fronto-parietal network and $\\alpha$ is the learning rate. E2 is chosen otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_based_learning(R,R_vta,rewarded_stimulus,parameters,persistent_activity_areas,c_VTA_DA_E1,c_VTA_DA_E2):\n",
    "        num_iterations = parameters['trial_length']/parameters['dt']\n",
    "        ping_on_timestep = int(parameters['ping_on']/parameters['dt'])\n",
    "        ping_off_timestep = int(parameters['ping_off']/parameters['dt'])\n",
    "        # Calculate the average delay period activity in excitatory population 1 in all the areas that show persistent activity experimentally\n",
    "        population1_ping_activity = np.mean(R[ping_on_timestep:ping_off_timestep,np.argwhere(persistent_activity_areas)[:,0],0])\n",
    "        # Now do the same for population 2\n",
    "        population2_ping_activity = np.mean(R[ping_on_timestep:ping_off_timestep,np.argwhere(persistent_activity_areas)[:,0],1])\n",
    "\n",
    "            \n",
    "        if rewarded_stimulus == 1:\n",
    "            if population1_ping_activity>population2_ping_activity:\n",
    "                reward = 1\n",
    "                \n",
    "                c_VTA_DA_E1 = c_VTA_DA_E1 + parameters['learning_rate_up']*(1 - c_VTA_DA_E1)\n",
    "            else:\n",
    "                reward = 0\n",
    "                c_VTA_DA_E2 = c_VTA_DA_E2 - parameters['learning_rate_down']*(c_VTA_DA_E2)\n",
    "\n",
    "        elif rewarded_stimulus == 2:\n",
    "            if population1_ping_activity<population2_ping_activity:\n",
    "                reward = 1\n",
    "                c_VTA_DA_E2 = c_VTA_DA_E2 + parameters['learning_rate_up']*(1 - c_VTA_DA_E2)\n",
    "\n",
    "            else:\n",
    "                reward = 0\n",
    "                c_VTA_DA_E1 = c_VTA_DA_E1 - parameters['learning_rate_down']*(c_VTA_DA_E1)\n",
    "\n",
    "        return(c_VTA_DA_E1,c_VTA_DA_E2,reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_areas(start_time,end_time,num_areas,area_list_SLN,R,parameters,pops_to_show,trial):\n",
    "    fig=plt.figure(figsize=(16,90), dpi= 80, facecolor='w', edgecolor='k')\n",
    "    plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "    for i in range(1,num_areas+1):\n",
    "        ax = plt.subplot(num_areas,2,i)\n",
    "        ax.set_title(area_list_SLN[i-1])\n",
    "        # Plot the rates for the E1 soma\n",
    "        plt.subplots_adjust(hspace = 1)\n",
    "        if True in (pops == 'E1' for pops in pops_to_show):\n",
    "            # Plot the rates for the E1 soma\n",
    "            plt.plot(np.arange((start_time-1)*brian2.second,(end_time-1)*brian2.second,PARAMS['dt']),R[trial,np.arange(int(start_time/PARAMS['dt']),int(end_time/PARAMS['dt']),1),i-1,0],color='r')\n",
    "        if True in (pops == 'E2' for pops in pops_to_show):\n",
    "            # Plot the rates for the E2 soma\n",
    "            plt.plot(np.arange((start_time-1)*brian2.second,(end_time-1)*brian2.second,PARAMS['dt']),R[trial,np.arange(int(start_time/PARAMS['dt']),int(end_time/PARAMS['dt']),1),i-1,1],color='b')\n",
    "        if True in (pops == 'PV' for pops in pops_to_show):\n",
    "            # Plot the rates for the PV population\n",
    "            plt.plot(np.arange((start_time-1)*brian2.second,(end_time-1)*brian2.second,PARAMS['dt']),R[trial,np.arange(int(start_time/PARAMS['dt']),int(end_time/PARAMS['dt']),1),i-1,4],color='#1b7837')\n",
    "        if True in (pops == 'SST1' for pops in pops_to_show):\n",
    "            # Plot the rates for the SST1 population\n",
    "            plt.plot(np.arange((start_time-1)*brian2.second,(end_time-1)*brian2.second,PARAMS['dt']),R[trial,np.arange(int(start_time/PARAMS['dt']),int(end_time/PARAMS['dt']),1),i-1,5],color='#b35806')\n",
    "        if True in (pops == 'SST2' for pops in pops_to_show):\n",
    "            # Plot the rates for the SST2 population\n",
    "            plt.plot(np.arange((start_time-1)*brian2.second,(end_time-1)*brian2.second,PARAMS['dt']),R[trial,np.arange(int(start_time/PARAMS['dt']),int(end_time/PARAMS['dt']),1),i-1,6],color='#b35806')\n",
    "        if True in (pops == 'VIP1' for pops in pops_to_show):\n",
    "            # Plot the rates for the VIP1 population\n",
    "            plt.plot(np.arange((start_time-1)*brian2.second,(end_time-1)*brian2.second,PARAMS['dt']),R[trial,np.arange(int(start_time/PARAMS['dt']),int(end_time/PARAMS['dt']),1),i-1,7],color='#542788')\n",
    "        if True in (pops == 'VIP2' for pops in pops_to_show):\n",
    "            # Plot the rates for the VIP2 population\n",
    "            plt.plot(np.arange((start_time-1)*brian2.second,(end_time-1)*brian2.second,PARAMS['dt']),R[trial,np.arange(int(start_time/PARAMS['dt']),int(end_time/PARAMS['dt']),1),i-1,8],color='#542788')\n",
    "\n",
    "        # Plot the stimulation time\n",
    "        plt.plot([parameters['stim_on']-1*brian2.second,parameters['stim_off']-1*brian2.second],[np.max(R[trial,:,i-1,:2]+0.05*np.max(R[trial,:,i-1,:2])),np.max(R[trial,:,i-1,:2]+0.05*np.max(R[trial,:,i-1,:2]))],color='r',linewidth=5.0)\n",
    "\n",
    "        # Plot the distractor time\n",
    "        plt.plot([parameters['distract_on']-1*brian2.second,parameters['distract_off']-1*brian2.second],[np.max(R[trial,:,i-1,:2]+0.05*np.max(R[trial,:,i-1,:2])),np.max(R[trial,:,i-1,:2]+0.05*np.max(R[trial,:,i-1,:2]))],color='b',linewidth=5.0)\n",
    "\n",
    "        # Plot the reward time\n",
    "        plt.plot([parameters['ping_on']-1*brian2.second,parameters['ping_off']-1*brian2.second],[np.max(R[trial,:,i-1,:2]+0.05*np.max(R[trial,:,i-1,:2])),np.max(R[trial,:,i-1,:2]+0.05*np.max(R[trial,:,i-1,:2]))],color='y',linewidth=5.0)\n",
    "\n",
    "        \n",
    "        # place text above the black line\n",
    "        axes = plt.gca()\n",
    "        if i==1:\n",
    "            axes.text(0.15, 1.2,'External stimulation to', transform=axes.transAxes, fontsize=10, verticalalignment='top')\n",
    "\n",
    "        plt.legend(pops_to_show)\n",
    "        plt.xlabel('time (s)')\n",
    "        plt.ylabel('firing rate (Hz)')\n",
    "        plt.ylim(0, 40) \n",
    "\n",
    "\n",
    "    # os.system('say \"finished\"')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_area(start_time,end_time,num_areas,area_list_SLN,R,parameters,pops_to_show,area_to_show,filename,trial):\n",
    "\n",
    "    i = area_list_SLN.index(area_to_show)+1\n",
    "\n",
    "    fig=plt.figure(figsize=(4,2), dpi= 80, facecolor='w', edgecolor='k')\n",
    "    plt.rcParams.update({'font.size': 25})\n",
    "\n",
    "#     plt.title(area_to_show)\n",
    "    if True in (pops == 'E1' for pops in pops_to_show):\n",
    "        # Plot the rates for the E1 soma\n",
    "        plt.plot(np.arange((start_time-1)*brian2.second,(end_time-1)*brian2.second,PARAMS['dt']),R[trial,np.arange(int(start_time/PARAMS['dt']),int(end_time/PARAMS['dt']),1),i-1,0],color='r')\n",
    "    if True in (pops == 'E2' for pops in pops_to_show):\n",
    "        # Plot the rates for the E2 soma\n",
    "        plt.plot(np.arange((start_time-1)*brian2.second,(end_time-1)*brian2.second,PARAMS['dt']),R[trial,np.arange(int(start_time/PARAMS['dt']),int(end_time/PARAMS['dt']),1),i-1,1],color='b')\n",
    "    if True in (pops == 'PV' for pops in pops_to_show):\n",
    "        # Plot the rates for the PV population\n",
    "        plt.plot(np.arange((start_time-1)*brian2.second,(end_time-1)*brian2.second,PARAMS['dt']),R[trial,np.arange(int(start_time/PARAMS['dt']),int(end_time/PARAMS['dt']),1),i-1,4],color='#1b7837')\n",
    "    if True in (pops == 'SST1' for pops in pops_to_show):\n",
    "        # Plot the rates for the SST1 population\n",
    "        plt.plot(np.arange((start_time-1)*brian2.second,(end_time-1)*brian2.second,PARAMS['dt']),R[trial,np.arange(int(start_time/PARAMS['dt']),int(end_time/PARAMS['dt']),1),i-1,5],color='#b35806')\n",
    "    if True in (pops == 'SST2' for pops in pops_to_show):\n",
    "        # Plot the rates for the SST2 population\n",
    "        plt.plot(np.arange((start_time-1)*brian2.second,(end_time-1)*brian2.second,PARAMS['dt']),R[trial,np.arange(int(start_time/PARAMS['dt']),int(end_time/PARAMS['dt']),1),i-1,6],color='#b35806')\n",
    "    if True in (pops == 'VIP1' for pops in pops_to_show):\n",
    "        # Plot the rates for the VIP1 population\n",
    "        plt.plot(np.arange((start_time-1)*brian2.second,(end_time-1)*brian2.second,PARAMS['dt']),R[trial,np.arange(int(start_time/PARAMS['dt']),int(end_time/PARAMS['dt']),1),i-1,7],color='#542788')\n",
    "    if True in (pops == 'VIP2' for pops in pops_to_show):\n",
    "        # Plot the rates for the VIP2 population\n",
    "        plt.plot(np.arange((start_time-1)*brian2.second,(end_time-1)*brian2.second,PARAMS['dt']),R[trial,np.arange(int(start_time/PARAMS['dt']),int(end_time/PARAMS['dt']),1),i-1,8],color='#542788')\n",
    "\n",
    "    axes = plt.gca()\n",
    "#     axes.text(0.1, 1.03,'cue', transform=axes.transAxes, fontsize=20, verticalalignment='top',color='r')\n",
    "#     axes.text(0.3, 1.03,'distractor', transform=axes.transAxes, fontsize=20, verticalalignment='top',color='b')\n",
    "    # Plot the stimulation time\n",
    "    plt.plot([parameters['stim_on']-6*brian2.second,parameters['stim_off']-6*brian2.second],[np.max(R[trial,:,i-1,5:]+0.05*np.max(R[trial,:,i-1,5:])),np.max(R[trial,:,i-1,5:]+0.05*np.max(R[trial,:,i-1,5:]))],color='r',linewidth=5.0)\n",
    "    # Plot the distractor time\n",
    "    plt.plot([parameters['distract_on']-6*brian2.second,parameters['distract_off']-6*brian2.second],[np.max(R[trial,:,i-1,5:]+0.05*np.max(R[trial,:,i-1,5:])),np.max(R[trial,:,i-1,5:]+0.05*np.max(R[trial,:,i-1,5:]))],color='b',linewidth=5.0)\n",
    "\n",
    "    # place text above the black line\n",
    "    # Shrink current axis by 20%\n",
    "\n",
    "#     plt.legend(pops_to_show,loc=(0.9,0.8),fontsize=15)\n",
    "#     plt.xlabel('time (s)')\n",
    "#     plt.ylabel('firing rate (Hz)')\n",
    "    plt.ylim(0, 50) \n",
    "\n",
    "    # Hide the right and top spines\n",
    "    axes.spines['right'].set_visible(False)\n",
    "    axes.spines['top'].set_visible(False)\n",
    "\n",
    "    # Only show ticks on the left and bottom spines\n",
    "    axes.yaxis.set_ticks_position('left')\n",
    "    axes.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "    fig.savefig(filename+'.pdf', dpi=300,bbox_inches='tight',transparent=True)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Run large-scale working memory model\n",
    "num_trials = 90\n",
    "num_iterations = int(PARAMS['trial_length']/PARAMS['dt'])\n",
    "\n",
    "rewards = np.zeros((num_trials))\n",
    "c_VTA_DA_E1 = PARAMS['c_VTA_DA_E1_init']\n",
    "c_VTA_DA_E2 = PARAMS['c_VTA_DA_E2_init']\n",
    "\n",
    "stimulus_order_all_trials = np.random.randint(1,3,num_trials)\n",
    "\n",
    "# Load in the anatomical data\n",
    "(sln, fln, hierarchy, area_list_SLN,\n",
    "        df_fln, df_sln, d1_density_raw, spine_count_raw, df_raw_anatomy,persistent_activity_areas) = load_anatomy()\n",
    "\n",
    "\n",
    "# Prepare all the connectivity matrices for the cortex\n",
    "(pops, num_pops, num_e_pops, num_areas, e_grad, g_adapt, ampa_frac, nmda_frac\n",
    " , J_nmda, J_ampa, J_gaba, J_gaba_dend, W_superficial, W_deep, lr_targets\n",
    " , nmda_da_grad, e_pv_da_mat, e_sst_da_mat, m_da_grad,g_m,lr_targets_FEF,d1_grad) = prepare_connectivity(PARAMS,spine_count_raw,fln,sln,d1_density_raw)\n",
    "\n",
    "# Prepare all the connectivity matrices for the VTA\n",
    "(W_vta_ctx,J_vta_local,num_vta_pops,pops_vta,I_background_vta) = prepare_vta_connectivity(PARAMS,c_VTA_DA_E1,c_VTA_DA_E2)\n",
    "\n",
    "# Initialise all the variables\n",
    "(num_iterations,R,s_nmda,s_ampa,s_gaba,s_gaba_dend,s_adapt\n",
    "           ,I_ext,I_lr_nmda,I_lr_ampa,I_local_nmda,I_local_ampa,I_local_gaba\n",
    "           ,I_soma_dend,I_total,I_exc_dend,I_inh_dend,I_local_gaba_dend,I_adapt\n",
    "           ,I_0,I_noise,noise_rhs,I_lr_nmda_vta,I_lr_ampa_vta,I_local_nmda_vta\n",
    "           ,I_local_ampa_vta,I_local_gaba_vta,total_vta_input,R_vta,s_nmda_vta\n",
    "           ,s_ampa_vta,s_gaba_vta,dyn_da_rel_ctx,dyn_da_rel_vta,s_nmda_stp,s_ampa_stp,x,u) = initialise_variables(PARAMS,num_areas,num_pops,num_e_pops,area_list_SLN,stimulus_order_all_trials[0])\n",
    "\n",
    "# reward the first stimulus on the first 5 trials, and then switch the rule\n",
    "rewarded_stim = np.concatenate((np.concatenate((np.ones((int(num_trials/3),1)), 2*np.ones((int(num_trials/3),1))), axis=0) , np.ones((int(num_trials/3),1))), axis=0)\n",
    "# rewarded_stim = np.ones(1)\n",
    "R_all_trials = np.zeros((num_trials,num_iterations,num_areas,num_pops)) * brian2.Hz\n",
    "R_vta_all_trials = np.zeros((num_trials,num_iterations,num_vta_pops)) * brian2.Hz\n",
    "dyn_da_rel_all_trials = np.zeros((num_trials,num_iterations))\n",
    "\n",
    "\n",
    "for current_trial in range(1,num_trials+1):\n",
    "\n",
    "    print(current_trial)\n",
    "    \n",
    "    # Prepare all the connectivity matrices for the cortex\n",
    "    (pops, num_pops, num_e_pops, num_areas, e_grad, g_adapt, ampa_frac, nmda_frac\n",
    "     , J_nmda, J_ampa, J_gaba, J_gaba_dend, W_superficial, W_deep, lr_targets\n",
    "     , nmda_da_grad, e_pv_da_mat, e_sst_da_mat, m_da_grad,g_m,lr_targets_FEF,d1_grad) = prepare_connectivity(PARAMS,spine_count_raw,fln,sln,d1_density_raw)\n",
    "\n",
    "    # Prepare all the connectivity matrices for the VTA\n",
    "    (W_vta_ctx,J_vta_local,num_vta_pops,pops_vta,I_background_vta)  = prepare_vta_connectivity(PARAMS,c_VTA_DA_E1,c_VTA_DA_E2)\n",
    "\n",
    "    # Initialise all the variables\n",
    "    (num_iterations,R,s_nmda,s_ampa,s_gaba,s_gaba_dend,s_adapt\n",
    "           ,I_ext,I_lr_nmda,I_lr_ampa,I_local_nmda,I_local_ampa,I_local_gaba\n",
    "           ,I_soma_dend,I_total,I_exc_dend,I_inh_dend,I_local_gaba_dend,I_adapt\n",
    "           ,I_0,I_noise,noise_rhs,I_lr_nmda_vta,I_lr_ampa_vta,I_local_nmda_vta\n",
    "           ,I_local_ampa_vta,I_local_gaba_vta,total_vta_input,R_vta,s_nmda_vta\n",
    "           ,s_ampa_vta,s_gaba_vta,dyn_da_rel_ctx,dyn_da_rel_vta,s_nmda_stp,s_ampa_stp,x,u) = initialise_variables(PARAMS,num_areas,num_pops,num_e_pops,area_list_SLN,stimulus_order_all_trials[current_trial-1])\n",
    "\n",
    "    # Run the simulation\n",
    "    (R,dyn_da_rel_ctx,dyn_da_rel_vta,x,u,R_vta) = large_scale_da_model(pops, num_pops, num_e_pops, num_areas, e_grad, g_adapt, ampa_frac, nmda_frac\n",
    "                          , J_nmda, J_ampa, J_gaba, J_gaba_dend, W_superficial, W_deep, lr_targets\n",
    "                          , nmda_da_grad, e_pv_da_mat, e_sst_da_mat, m_da_grad,num_iterations,R,s_nmda\n",
    "                          ,s_ampa,s_gaba,s_gaba_dend,s_adapt\n",
    "                          ,I_ext,I_lr_nmda,I_lr_ampa,I_local_nmda,I_local_ampa,I_local_gaba\n",
    "                          ,I_soma_dend,I_total,I_exc_dend,I_inh_dend,I_local_gaba_dend,I_adapt\n",
    "                          ,I_0,I_noise,noise_rhs,PARAMS,lr_targets_FEF,I_lr_nmda_vta,I_lr_ampa_vta\n",
    "                          ,I_local_nmda_vta,I_local_ampa_vta,I_local_gaba_vta,total_vta_input,R_vta\n",
    "                          ,s_nmda_vta,s_ampa_vta,s_gaba_vta,dyn_da_rel_ctx,dyn_da_rel_vta,I_background_vta,W_vta_ctx\n",
    "                          ,J_vta_local,d1_grad,s_nmda_stp,s_ampa_stp,x,u)\n",
    "\n",
    "    \n",
    "    # Update weights in VTA based on outcome of the trial\n",
    "    (c_VTA_DA_E1,c_VTA_DA_E2,reward) = reward_based_learning(R,R_vta,rewarded_stim[current_trial-1],PARAMS,persistent_activity_areas,c_VTA_DA_E1,c_VTA_DA_E2)\n",
    "    \n",
    "    rewards[current_trial-1] = reward\n",
    "    R_all_trials[current_trial-1,:,:,:] = R\n",
    "    R_vta_all_trials[current_trial-1,:,:] = R_vta\n",
    "    dyn_da_rel_all_trials[current_trial-1,:] = dyn_da_rel_ctx\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pops_to_plot = ['E1','E2']\n",
    "start_time = 5.5\n",
    "end_time = 13\n",
    "trial = 34\n",
    "plot_all_areas(start_time,end_time,num_areas,area_list_SLN,R_all_trials,PARAMS,pops_to_plot,trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'firing rate (Hz)')"
      ]
     },
     "execution_count": 868,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 480x160 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fig=plt.figure(figsize=(6,2), dpi= 80, facecolor='w', edgecolor='k')\n",
    "plt.rcParams.update({'font.size': 25})\n",
    "\n",
    "# plt.plot(dyn_da_rel[10000:])\n",
    "plt.plot(np.arange((start_time-6)*brian2.second,(end_time-6)*brian2.second,PARAMS['dt']),R_vta[np.arange(int(start_time/PARAMS['dt']),int(end_time/PARAMS['dt']),1),0])\n",
    "plt.plot(np.arange((start_time-6)*brian2.second,(end_time-6)*brian2.second,PARAMS['dt']),R_vta[np.arange(int(start_time/PARAMS['dt']),int(end_time/PARAMS['dt']),1),1])\n",
    "\n",
    "plt.legend(['vta DA','vta I'],loc=(1.04,0))\n",
    "# plt.plot(x[:,0,0])\n",
    "# plt.plot(u[:,0,0])\n",
    "# plt.plot(x[:,0,0]*u[:,0,0]/(PARAMS['x0']*PARAMS['u0']))\n",
    "# plt.plot(x[:,0,0]*u[:,0,0])\n",
    "# plt.plot(R[:,0,0])\n",
    "\n",
    "axes = plt.gca()\n",
    "# Plot the stimulation time\n",
    "plt.plot([PARAMS['stim_on']-6*brian2.second,PARAMS['stim_off']-6*brian2.second],[80,80],color='r',linewidth=5.0)\n",
    "# # Plot the distractor time\n",
    "plt.plot([PARAMS['distract_on']-6*brian2.second,PARAMS['distract_off']-6*brian2.second],[80,80],color='b',linewidth=5.0)\n",
    "plt.plot([PARAMS['ping_on']-6*brian2.second,PARAMS['ping_off']-6*brian2.second],[80,80],color='k',linewidth=5.0)\n",
    "\n",
    "# Hide the right and top spines\n",
    "axes.spines['right'].set_visible(False)\n",
    "axes.spines['top'].set_visible(False)\n",
    "\n",
    "# Only show ticks on the left and bottom spines\n",
    "axes.yaxis.set_ticks_position('left')\n",
    "axes.xaxis.set_ticks_position('bottom')\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('firing rate (Hz)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Cortical DA')"
      ]
     },
     "execution_count": 869,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 480x160 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure(figsize=(6,2), dpi= 80, facecolor='w', edgecolor='k')\n",
    "plt.rcParams.update({'font.size': 25})\n",
    "\n",
    "# plt.plot(dyn_da_rel[10000:])\n",
    "plt.plot(np.arange((start_time-6)*brian2.second,(end_time-6)*brian2.second,PARAMS['dt']),dyn_da_rel_ctx[np.arange(int(start_time/PARAMS['dt']),int(end_time/PARAMS['dt']),1)])\n",
    "\n",
    "# plt.legend(['vta DA','vta I'],loc=(1.04,0))\n",
    "# plt.plot(x[:,0,0])\n",
    "# plt.plot(u[:,0,0])\n",
    "# plt.plot(x[:,0,0]*u[:,0,0]/(PARAMS['x0']*PARAMS['u0']))\n",
    "# plt.plot(x[:,0,0]*u[:,0,0])\n",
    "# plt.plot(R[:,0,0])\n",
    "\n",
    "axes = plt.gca()\n",
    "# Plot the stimulation time\n",
    "plt.plot([PARAMS['stim_on']-6*brian2.second,PARAMS['stim_off']-6*brian2.second],[3,3],color='r',linewidth=5.0)\n",
    "# # Plot the distractor time\n",
    "plt.plot([PARAMS['distract_on']-6*brian2.second,PARAMS['distract_off']-6*brian2.second],[3,3],color='b',linewidth=5.0)\n",
    "plt.plot([PARAMS['ping_on']-6*brian2.second,PARAMS['ping_off']-6*brian2.second],[3,3],color='k',linewidth=5.0)\n",
    "\n",
    "# Hide the right and top spines\n",
    "axes.spines['right'].set_visible(False)\n",
    "axes.spines['top'].set_visible(False)\n",
    "\n",
    "# Only show ticks on the left and bottom spines\n",
    "axes.yaxis.set_ticks_position('left')\n",
    "axes.xaxis.set_ticks_position('bottom')\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('Cortical DA')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(rewards[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(rewards[30:60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(rewards[60:90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999612021304\n"
     ]
    }
   ],
   "source": [
    "print(c_VTA_DA_E1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.639516708209\n"
     ]
    }
   ],
   "source": [
    "print(c_VTA_DA_E2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 1 1 2 1 2 1 2 2 2 2 1 2 1 2 2 2 1 1 1 2 2 1 2 2 2 1 2 2 2 1 1 2 2 2 2\n",
      " 2 1 2 2 1 1 1 2 2 2 1 2 1 2 1 2 2 1 2 1 1 1 2 1 2 2 1 2 1 1 2 1 1 1 1 1 1\n",
      " 1 2 1 2 1 1 2 1 1 1 1 2 2 2 1 1]\n"
     ]
    }
   ],
   "source": [
    "stimulus_order_all_trials = np.random.randint(1,3,num_trials)\n",
    "\n",
    "print(stimulus_order_all_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "rewarded_stim = np.concatenate((np.concatenate((np.ones((int(num_trials/3),1)), 2*np.ones((int(num_trials/3),1))), axis=0) , np.ones((int(num_trials/3),1))), axis=0)\n",
    "\n",
    "print(rewarded_stim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 1)\n"
     ]
    }
   ],
   "source": [
    "print(rewarded_stim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the run-in time \n",
    "R_all_trials_short = copy.deepcopy(R_all_trials[:,10000:,:,:])\n",
    "R_vta_all_trials_short = copy.deepcopy(R_vta_all_trials[:,10000:,:])\n",
    "dyn_da_rel_all_trials_short = copy.deepcopy(dyn_da_rel_all_trials[:,10000:])\n",
    "\n",
    "data = {}\n",
    "\n",
    "data.update({'R': R_all_trials_short}) # firing rates cortex\n",
    "data.update({'R_vta': R_vta_all_trials_short}) # firing rates VTA\n",
    "data.update({'da_rel': dyn_da_rel_all_trials_short}) # cortical dopamine availability\n",
    "data.update({'rewards': rewards}) # reward history\n",
    "\n",
    "\n",
    "sio.savemat('model_outputs/cortex_vta_learning_soltani_90trials.mat', data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
