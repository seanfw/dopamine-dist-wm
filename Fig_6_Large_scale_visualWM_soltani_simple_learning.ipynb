{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to add a VTA, dynamic dopamine release and simple reinforcement learning to the connectome-based dynamical model.\n",
    "\n",
    "Sean Froudist-Walsh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's get what we need together\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import numpy.matlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas\n",
    "import scipy.io as sio\n",
    "import brian2\n",
    "import os\n",
    "import copy\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the function that transforms input current to changes in firing rate for excitatory neurons (Abbott and Chance, 2005). \n",
    "<br>\n",
    "$$r_E = \\frac{aI_{total,E} - b}{1 - e^{-d(aI_{total,E} - b)}} $$\n",
    "\n",
    "Update the firing rates of the interneurons using a threshold linear input/output function\n",
    "$$ \\begin{cases}\n",
    "  r_I = c_II_{total,I} + r_0 & \\text{for } I_{total,I}\\ge -r_0/c_I\\\\    \n",
    "  r_I = 0     & \\text{otherwise }  \n",
    "\\end{cases} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def current_to_frequency(input_current,population_type,parameters):\n",
    "    if population_type == 'E':\n",
    "        a = parameters['a_e']\n",
    "        b = parameters['b_e']\n",
    "        d = parameters['d_e']\n",
    "        return np.divide((a*input_current - b),(1 - np.exp(-d*(a*input_current - b))))\n",
    "    if population_type == 'PV':\n",
    "        c_I = parameters['c_I_pv']\n",
    "        r_0 = parameters['r_0_pv']\n",
    "        r = np.maximum(c_I*input_current + r_0,0)\n",
    "        return r\n",
    "    if population_type == 'SST':\n",
    "        c_I = parameters['c_I_sst']\n",
    "        r_0 = parameters['r_0_sst']\n",
    "        r = np.maximum(c_I*input_current + r_0,0)\n",
    "        return r\n",
    "    if population_type == 'VIP':\n",
    "        c_I = parameters['c_I_vip']\n",
    "        r_0 = parameters['r_0_vip']\n",
    "        r = np.maximum(c_I*input_current + r_0,0)\n",
    "        return r\n",
    "    if population_type == 'DA':\n",
    "        c_I = parameters['c_I_da']\n",
    "        r_0 = parameters['r_0_da']\n",
    "        r = np.maximum(c_I*input_current + r_0,0)\n",
    "        return r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the current formulation of the dendrite input-output function (presuming $I_{inh}$ is negative)\n",
    "<br>\n",
    "<br>\n",
    "$$ \n",
    "I_{soma,dendrite} = f_I(I_{exc},I_{inh}) = \n",
    "c_1.\\biggl[\\tanh\\biggl(\\dfrac{I_{exc} + c_3*I_{inh} + c_4}{c_5 e^{-I_{inh}/c6}}\\biggr)\\biggr] + c_2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dendrite_input_output(exc_current,inh_current,parameters):\n",
    "    c1 = parameters['c1']\n",
    "    c2 = parameters['c2']\n",
    "    c3 = parameters['c3']\n",
    "    c4 = parameters['c4']\n",
    "    c5 = parameters['c5']\n",
    "    c6 = parameters['c6']\n",
    "    \n",
    "    beta = c5*np.exp(-inh_current/c6)\n",
    "    \n",
    "    return c1*(np.tanh((exc_current +c3*inh_current + c4)/beta)) + c2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the NMDA derivative\n",
    "<br>\n",
    "$$ \\frac{dS_{NMDA}}{dt} = -\\frac{S_{NMDA}}{\\tau_{NMDA}} + x_0u_0(1 - S_{NMDA})\\gamma r_E$$\n",
    "(Wong & Wang, 2006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NMDA_deriv(S_NMDA_prev,rate_now,parameters):\n",
    "    \n",
    "    return -S_NMDA_prev/parameters['tau_nmda'] + parameters['x0']*parameters['u0']*parameters['gamma_nmda']*(1 - S_NMDA_prev)*rate_now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the AMPA derivative \n",
    "<br>\n",
    "$$ \\frac{dS_{AMPA}}{dt} = -\\frac{S_{AMPA}}{\\tau_{AMPA}} + x_0u_0\\gamma_{AMPA}r_E$$\n",
    "(Wong & Wang, 2006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AMPA_deriv(S_AMPA_prev,rate_now,parameters):\n",
    "    \n",
    "    return -S_AMPA_prev/parameters['tau_ampa'] + parameters['x0']*parameters['u0']*parameters['gamma_ampa']*rate_now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the GABA derivative\n",
    "<br>\n",
    "$$ \\frac{dS_{GABA}}{dt} = -\\frac{S_{GABA}}{\\tau_{GABA}} + \\gamma_Ir_I$$\n",
    "(Wong & Wang, 2006)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GABA_deriv(S_GABA_prev,rate_now,parameters,cell_section):\n",
    "    if cell_section == 'soma':\n",
    "        return -S_GABA_prev/parameters['tau_gaba'] + parameters['gamma_gaba']*rate_now \n",
    "    elif cell_section == 'dendrite':\n",
    "        return -S_GABA_prev/parameters['tau_gaba_dend'] + parameters['gamma_gaba']*rate_now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the adaptation current derivative\n",
    "$$ \\frac{dS_{a}}{dt} = -\\frac{S_{a}}{\\tau_{a}} + r $$\n",
    "(Engel & Wang, 2001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptation_deriv(S_a_prev,rate_now,parameters):\n",
    "    return -S_a_prev/parameters['tau_adapt'] + rate_now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several of dopamine's effects are models with a sigmoid function (such as how release gets converted to fraction of occupied D1 receptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_DA(height,midpoint,slope):\n",
    "     return np.exp(slope*(height-midpoint))/(1 + np.exp(slope*(height-midpoint)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the dopamine concentration function\n",
    "$$ \\frac{d[DA]}{dt} = -\\frac{[DA]}{\\tau_{DA}} + \\gamma_{DA}r_{VTA_{DA}} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DAconc_deriv(DA_prev,DA_rate_now,parameters,brain_region):\n",
    "    if brain_region == 'cortex':\n",
    "        return -DA_prev/parameters['tau_DA_ctx'] + parameters['gamma_DA_ctx']*DA_rate_now\n",
    "    elif brain_region == 'vta':\n",
    "        return -DA_prev/parameters['tau_DA_vta'] + parameters['gamma_DA_vta']*DA_rate_now\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the short-term facilitation (usage of synaptic resources - related to presynaptic calcium\n",
    "$$ \\frac{du}{dt} = \\frac{U - u}{\\tau_{u}} + U(1-u)r $$\n",
    "(Mongillo et al., 2008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def STF_deriv(rate_prev,u_prev,parameters):\n",
    "    return (parameters['U_baseline'] - u_prev)/parameters['tau_u'] + parameters['U_baseline']*(1- u_prev)*rate_prev\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the short-term depression (total store of available vesicles) - is depleted by u (usage)\n",
    "$$ \\frac{dx}{dt} = \\frac{1 - x}{\\tau_{x}} - uxr $$\n",
    "(Mongillo et al., 2008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def STD_deriv(rate_prev,x_prev,u_prev,parameters):\n",
    "    return (1 - x_prev)/parameters['tau_x'] - u_prev*x_prev*rate_prev\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the NMDA derivative with STP\n",
    "<br>\n",
    "$$ \\frac{dS_{NMDA}}{dt} = -\\frac{S_{NMDA}}{\\tau_{NMDA}} + xu(1 - S_{NMDA})\\gamma r_E$$\n",
    "(Wong & Wang, 2006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NMDA_deriv_STP(S_NMDA_prev,rate_now,parameters,u_prev):\n",
    "    # STF only\n",
    "    return -S_NMDA_prev/parameters['tau_nmda'] + parameters['x0']*u_prev*parameters['gamma_nmda']*(1 - S_NMDA_prev)*rate_now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the AMPA derivative with STP\n",
    "<br>\n",
    "$$ \\frac{dS_{AMPA}}{dt} = -\\frac{S_{AMPA}}{\\tau_{AMPA}} + xu\\gamma_{AMPA}r_E$$\n",
    "(Wong & Wang, 2006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AMPA_deriv_STP(S_AMPA_prev,rate_now,parameters,u_prev):\n",
    "    # STF only\n",
    "    return -S_AMPA_prev/parameters['tau_ampa'] + parameters['x0']*u_prev*parameters['gamma_ampa']*rate_now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = {# dendrite I/O function parameters\n",
    "\t\t  'c1': 120 * brian2.pA,\n",
    "          'c2': 136.24 * brian2.pA,\n",
    "          'c3': 7.0,\n",
    "          'c4': 0 * brian2.pA,\n",
    "          'c5': 9.64 * brian2.pA,\n",
    "          'c6': 20 * brian2.pA,\n",
    "          # Time constants\n",
    "          'tau_nmda': 60 * brian2.ms,\n",
    "          'tau_gaba': 5 * brian2.ms,\n",
    "          'tau_gaba_dend': 10 * brian2.ms,\n",
    "          'tau_ampa': 2 * brian2.ms,\n",
    "          'tau_rates': 2 * brian2.ms,\n",
    "          'tau_adapt': 0.1   * brian2.second, # new\n",
    "          'tau_DA_ctx': 2      * brian2.second, # DA reuptake (slow in cortex)\n",
    "          'tau_DA_vta': 0.0005      * brian2.second, # DA reuptake (fast in vta)\n",
    "          'tau_u': 0.2 * brian2.second, # s - facilitation\n",
    "          'tau_x': 0.2 * brian2.second, # s - depressing \n",
    "          'u0': 0.22, # baseline u\n",
    "          'x0': 0.87, # baseline x              \n",
    "          'U_baseline': 0.2,\n",
    "          # f-I curve parameters - E populations\n",
    "          'a_e': 0.5 * 0.27 * brian2.Hz / brian2.pA,\n",
    "          'b_e': 0.5 * 108 * brian2.Hz,\n",
    "          'd_e': 2 * 0.154 * brian2.second,\n",
    "\t\t  # f-I curve parameters - I populations\n",
    "          'c_I_pv': 330 * brian2.Hz / brian2.nA,\n",
    "          'c_I_sst': 132 * brian2.Hz / brian2.nA,\n",
    "          'c_I_vip': 132 * brian2.Hz / brian2.nA,\n",
    "          'c_I_da': 50 * brian2.Hz / brian2.nA,\n",
    "          # firing rate params\n",
    "          'r_0_e': 5 * brian2.Hz,\n",
    "          'r_0_pv': -95 * brian2.Hz,\n",
    "          'r_0_sst': -33 * brian2.Hz,\n",
    "          'r_0_vip': -33 * brian2.Hz,\n",
    "          'r_0_da': -5 * brian2.Hz,\n",
    "    \n",
    "          # rise rates\n",
    "          'gamma_nmda': 5*0.641 * 2,\n",
    "          'gamma_gaba': 2,\n",
    "          'gamma_ampa': 5*5,                       # unitless\n",
    "          'gamma_DA_ctx': 0.1, #amount of DA released in cortex in response to VTA DA neuron firing\n",
    "          'gamma_DA_vta': 500, #amount of DA released in VTA in response to VTA DA neuron firing\n",
    "\n",
    "          # local strengths E-->\n",
    "          'g_e_self': 0.18 * brian2.nA,\n",
    "          'g_e_cross': 0 * brian2.nA,\n",
    "          'g_pv_e' : 0.174   * brian2.nA,  \n",
    "          'g_sst_e_self' : 0.0435   * brian2.nA,  \n",
    "          'g_sst_e_cross' : 0.0435   * brian2.nA,  \n",
    "          'g_vip_e' : 0.058   * brian2.nA,  \n",
    "          # local strengths PV-->\n",
    "          'g_e_pv_min': -0.001 * brian2.nA, # dopamine dependent min PV->E strength\n",
    "          'g_e_pv_max': -0.4 * brian2.nA, # dopamine dependent max PV->E strength\n",
    "          'g_pv_self': -0.18 * brian2.nA,\n",
    "          # local strengths SST-->          \n",
    "          'g_pv_sst': -0.17 * brian2.nA,\n",
    "          'g_vip_sst': -0.1 * brian2.nA,\n",
    "          'g_e_sst_min': -0.09 * brian2.nA, # dopamine dependent min SST->E strength\n",
    "          'g_e_sst_max': -0.11 * brian2.nA, # dopamine dependent max SST->E strength\n",
    "          # local strengths VIP-->     \n",
    "          'g_sst_vip': -0.05 * brian2.nA,\n",
    "        # VTA strengths\n",
    "          'g_vta_da_I': -0.55 * brian2.nA,\n",
    "          'g_VTA_DA_ctx_E_scale': 0.047,\n",
    "          'g_VTA_I_ctx_E_scale': 0.02,\n",
    "          'c_VTA_DA_E1_init': 0.7,\n",
    "          'c_VTA_DA_E2_init': 1,\n",
    "\n",
    "\n",
    "    \n",
    "          # adaptation strengths\n",
    "          'g_adapt_e': -0.004 * brian2.nA,\n",
    "          'g_adapt_sst': -0.004 * brian2.nA,\n",
    "          'g_adapt_vip': -0.004 * brian2.nA,\n",
    "          # background currents\n",
    "          'I_background_e': 310 * brian2.pA,\n",
    "          'I_background_i': 300 * brian2.pA,\n",
    "          'I_background_dend': 30 * brian2.pA,\n",
    "          'I_background_da_vta': 350 * brian2.pA,\n",
    "          'I_background_i_vta': 250 * brian2.pA,\n",
    "    \n",
    "          # noise\n",
    "          'std_noise': 5 * brian2.pA,\n",
    "\n",
    "\n",
    "          # Long-range connectivity strengths\n",
    "          # projections from superficial layers to E cells\n",
    "          'mu_ee': 1.45,\n",
    "          # Long-range connectivity strengths\n",
    "          # projections from deep layers to I cells\n",
    "          'mu_ie': 2.24,\n",
    "          # Fraction of long-range superficial (E-->E) connections onto each population    \n",
    "          'lr_e_self_dend': 0.9,\n",
    "          'lr_e_cross_dend': 0.1,\n",
    "          # Fraction of long-range deep (E-->I) connections onto each population    \n",
    "          'lr_pv_e': 0.31,\n",
    "          'lr_sst_e_self': 0.22 ,\n",
    "          'lr_vip_e_self': 0.47,\n",
    "          # parameters for m current\n",
    "          'midpoint_m' : 0.85,#0.85\n",
    "          'slope_m' : 14,\n",
    "          'g_m' : -0.5  * brian2.nA,\n",
    "          # parameters for D1 occupancy\n",
    "          'midpoint_d1occ' : 1,\n",
    "          'slope_d1occ' : 2,\n",
    "          # parameters for DA modulation of NMDA\n",
    "          'midpoint_nmda_da' : 0.35,\n",
    "          'slope_nmda_da' : 10,\n",
    "          'g_nmda_da': 0.6,\n",
    "\n",
    "          # excitatory gradient parameters\n",
    "          'e_grad_min': 0.45,\n",
    "          # stimulus strength \n",
    "          'stim_strength': 0.1 * brian2.nA,\n",
    "    \n",
    "          # stimulus strength \n",
    "          'reward_strength': -0.2 * brian2.nA,\n",
    "\t\t  # squish connectivity matrix params\n",
    "          'b1': 0.3,\n",
    "\t\t  # AMPA/(AMPA+NMDA) fraction \n",
    "          'ampa_frac': 0.1,\n",
    "          'ampa_frac_pv': 0.2,\n",
    "          'dt': 0.5 * brian2.ms,\n",
    "          'trial_length': 13 * brian2.second,\n",
    "          'stim_on': 6 * brian2.second,\n",
    "          'stim_off': 6.4 * brian2.second,\n",
    "          'distract_on': 7 * brian2.second,\n",
    "          'distract_off': 7.4 * brian2.second,\n",
    "          'ping_on': 8 * brian2.second,\n",
    "          'ping_off': 8.4 * brian2.second,\n",
    "#           'reward_on': 8 * brian2.second,\n",
    "#           'reward_off': 9.9 * brian2.second,\n",
    "          # STD_\n",
    "          'learning_rate_up': 0.2,\n",
    "          'learning_rate_down': 0.2,\n",
    "          # dopamine release\n",
    "          'da_rel': 1.5}\n",
    "\n",
    "with open('large_scale_visualWM_DA_params.pck', 'wb') as f:\n",
    "    pickle.dump(PARAMS, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('large_scale_visualWM_DA_params.pck') as f:\n",
    "#     PARAMS_2 = pickle.load(f)\n",
    "\n",
    "\n",
    "# print(PARAMS_2['stim_strength'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in anatomical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_anatomy():\n",
    "    # Load in anatomical data file\n",
    "    subgraph_data = sio.loadmat('anatomical_data/beta_bin_hierarchy_subgraph.mat')\n",
    "    sln = subgraph_data['HierOrderedSLNsubgraph']\n",
    "    fln = subgraph_data['HierOrderedFLNsubgraph']\n",
    "    hierarchy = subgraph_data['hierarchy_vals_subgraph']\n",
    "\n",
    "\n",
    "    temp_list = subgraph_data['subgraph_hierarchical_order']\n",
    "    area_list_SLN = []\n",
    "    for row in temp_list:\n",
    "        v = '%s' % str(row[0][0])\n",
    "        area_list_SLN.append(v)\n",
    "\n",
    "    area_column_list  = ['from '+ mystring for mystring in area_list_SLN]\n",
    "    area_row_list  = ['to '+ mystring for mystring in area_list_SLN]\n",
    "\n",
    "    df_fln = pandas.DataFrame(fln , columns=area_column_list, index=area_row_list)\n",
    "\n",
    "    df_sln = pandas.DataFrame(sln , columns=area_column_list, index=area_row_list)\n",
    "\n",
    "    # load the receptor data\n",
    "    D1R_data = sio.loadmat('anatomical_data/D1R_lyon_regions.mat')\n",
    "\n",
    "    D1_density_raw = D1R_data['D1R_lyon_regions_40']\n",
    "\n",
    "    # load the spine count data\n",
    "    spine_data = sio.loadmat('anatomical_data/spine_count_lyon_regions.mat')\n",
    "\n",
    "    spine_count_raw = spine_data['spine_count_lyon_regions_40']\n",
    "\n",
    "    df_raw_anatomy = pandas.DataFrame(D1_density_raw, columns=['D1R'], index=area_list_SLN)\n",
    "    df_raw_anatomy.loc[:,'spines'] = spine_count_raw\n",
    "    df_raw_anatomy.loc[:,'hierarchy'] = hierarchy\n",
    "\n",
    "      \n",
    "    # Load in the list of areas that show persistent activity according to Leavitt et al\n",
    "    persistent_areas_experimental_mat = sio.loadmat('anatomical_data/persistent_areas_experimental.mat')\n",
    "    persistent_activity_areas_all = persistent_areas_experimental_mat['persistent_areas_data']\n",
    "    well_studied_areas = persistent_areas_experimental_mat['well_studied']\n",
    "    persistent_activity_areas = persistent_activity_areas_all*well_studied_areas\n",
    "    \n",
    "    \n",
    "    return (sln, fln, hierarchy, area_list_SLN,\n",
    "        df_fln, df_sln, D1_density_raw, spine_count_raw, df_raw_anatomy,persistent_activity_areas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_connectivity(parameters,spine_count_raw,fln,sln,d1_density_raw):\n",
    "\n",
    "    d1_occ = sigmoid_DA(parameters['da_rel'],parameters['midpoint_d1occ'],parameters['slope_d1occ'])\n",
    "\n",
    "    ######## Excitatory gradient ########\n",
    "    # scale spine count to lie within [0,1] range\n",
    "    min_spine_count = np.min(spine_count_raw)\n",
    "    spine_count_rescaled = spine_count_raw-min_spine_count\n",
    "    spine_grad = spine_count_rescaled/np.max(spine_count_rescaled)\n",
    "\n",
    "    # define the excitatory gradient to lie according to the spine count \n",
    "    e_grad_scaling_factor = 1 - parameters['e_grad_min'] \n",
    "    e_grad = parameters['e_grad_min'] + e_grad_scaling_factor*spine_grad\n",
    "\n",
    "    ######## Local connectivity ########\n",
    "    # set up the local connectivity matrix\n",
    "    J =  np.array([[parameters['g_e_self'] , parameters['g_e_cross'], 0, 0, parameters['g_pv_e'], parameters['g_sst_e_self'], parameters['g_sst_e_cross'],parameters['g_vip_e'],0],\n",
    "                   [parameters['g_e_cross'] , parameters['g_e_self'],  0, 0, parameters['g_pv_e'], parameters['g_sst_e_cross'], parameters['g_sst_e_self'], 0, parameters['g_vip_e']],\n",
    "                   [0,0,0,0,0,0,0,0,0],\n",
    "                   [0,0,0,0,0,0,0,0,0],\n",
    "                  [parameters['g_e_pv_min'],parameters['g_e_pv_min'],0,0,parameters['g_pv_self'], 0, 0,0,0],\n",
    "                  [0,0,0,0,parameters['g_pv_sst'], 0, 0,parameters['g_vip_sst'],0],\n",
    "                  [0,0,0,0,parameters['g_pv_sst'], 0, 0, 0,parameters['g_vip_sst']],\n",
    "                  [0,0,0,0,0,parameters['g_sst_vip'],0,0,0],\n",
    "                  [0,0,0,0,0,0,parameters['g_sst_vip'],0,0]\n",
    "                  ]).T * brian2.amp\n",
    "\n",
    "\n",
    "    pops = ['E1soma','E2soma','E1dend','E2dend','PV','SST1','SST2','VIP1','VIP2']\n",
    "    pops_column_list  = ['from '+ mystring for mystring in pops]\n",
    "    pops_row_list  = ['to '+ mystring for mystring in pops]\n",
    "\n",
    "    J_display = J*(1/brian2.pA)\n",
    "    df_J = pandas.DataFrame(J_display, columns=pops_column_list, index=pops_row_list)\n",
    "    df_J\n",
    "\n",
    "    ######### numbers of areas, populations ##########\n",
    "\n",
    "    num_pops  = J.shape[0]\n",
    "    num_e_pops = 2\n",
    "    num_areas = fln.shape[0]\n",
    "\n",
    "    ######### adaptation ###########\n",
    "    g_adapt = np.array([parameters['g_adapt_e'],parameters['g_adapt_e'],0,0,0,\n",
    "                        parameters['g_adapt_sst'],parameters['g_adapt_sst'],parameters['g_adapt_vip']\n",
    "                        ,parameters['g_adapt_vip']])* brian2.amp \n",
    "\n",
    "    \n",
    "    g_m = np.array([parameters['g_m'],parameters['g_m'],0,0,0,0,0,0,0])* brian2.amp \n",
    "    \n",
    "    ######### AMPA/(AMPA+NMDA) fraction ##########\n",
    "\n",
    "    ampa_frac = np.array([parameters['ampa_frac'],parameters['ampa_frac'],parameters['ampa_frac'],parameters['ampa_frac']\n",
    "                          ,parameters['ampa_frac_pv'],parameters['ampa_frac'],parameters['ampa_frac']\n",
    "                          ,parameters['ampa_frac'],parameters['ampa_frac']])\n",
    "    nmda_frac = 1 - ampa_frac\n",
    "\n",
    "    J_nmda = J*((J>0).astype(np.int))\n",
    "    J_ampa = J*((J>0).astype(np.int))\n",
    "    J_gaba = J*((J<0).astype(np.int))\n",
    "\n",
    "    J_gaba_dend =  np.array([[0,0,0,0,0,parameters['g_e_sst_min'],0,0,0],\n",
    "                   [0,0,0,0,0,0,parameters['g_e_sst_min'],0,0]]) * brian2.amp \n",
    "\n",
    "    ####### LONG-RANGE CONNECTIONS ########\n",
    "    # Compress FLN\n",
    "    fln_squish = np.power(fln,parameters['b1'])\n",
    "    fln_rowtotal = np.sum(fln_squish,axis=1)\n",
    "    fln_rowtotal_mat = np.matlib.repmat(fln_rowtotal, num_areas,1).T\n",
    "    fln_squishnorm = fln_squish/fln_rowtotal_mat\n",
    "\n",
    "    # Isolate long-range connections from superficial layers\n",
    "    W_superficial = fln_squishnorm*sln\n",
    "    # Isolate long-range connections from deep layers\n",
    "    W_deep = fln_squishnorm*(1-sln)\n",
    "\n",
    "\n",
    "    # This matrix splits the long-range current onto each local population of cells\n",
    "    lr_targets = np.array([[0, 0,parameters['lr_e_self_dend'],parameters['lr_e_cross_dend']\n",
    "                                 ,parameters['lr_pv_e'],parameters['lr_sst_e_self'],0,parameters['lr_vip_e_self'],0],\n",
    "                                [0, 0, parameters['lr_e_cross_dend'], parameters['lr_e_self_dend']\n",
    "                                 ,parameters['lr_pv_e'],0,parameters['lr_sst_e_self'],0,parameters['lr_vip_e_self']]]).T * brian2.nA\n",
    "\n",
    "    # This matrix splits the long-range current onto each local population of cells - reflecting greater proportion of CR cells in FEF (Pouget et al., 2009)\n",
    "    lr_targets_FEF = np.array([[0, 0,parameters['lr_e_self_dend'],parameters['lr_e_cross_dend']\n",
    "                                 ,0.2,0.1,0,0.7,0],\n",
    "                                [0, 0, parameters['lr_e_cross_dend'], parameters['lr_e_self_dend']\n",
    "                                 ,0.2,0,0.1,0,0.7]]).T * brian2.nA\n",
    "\n",
    "    ##### Dopamine modulation #####\n",
    "    # scale_receptors to lie within [0,1] range\n",
    "    min_d1R = np.min(d1_density_raw)\n",
    "    d1R_rescaled = np.squeeze(d1_density_raw)-min_d1R\n",
    "    d1_grad = d1R_rescaled/np.max(d1R_rescaled)\n",
    "\n",
    "    # strength of excitatory currents through NMDA receptors increases with dopamine (Seamans et al., PNAS, 2001)\n",
    "    # To remove effect of dopamine on NMDA, while keeping other dopamine effects, set d1_occ here = 0\n",
    "    nmda_da_grad = 1 + parameters['g_nmda_da']*sigmoid_DA(d1_occ*np.expand_dims(d1_grad,axis=1),parameters['midpoint_nmda_da'],parameters['slope_nmda_da'])\n",
    "\n",
    "    # PV-->soma strength decreases with dopamine (Gao et al., J Neurosci, 2003)\n",
    "    # To remove effect of dopamine on PV-->E connections, while keeping other dopamine effects, set d1_occ here = 0\n",
    "    e_pv_da_grad = (parameters['g_e_pv_max'] + d1_occ*d1_grad*(parameters['g_e_pv_min'] - parameters['g_e_pv_max']))/parameters['g_e_pv_min']\n",
    "    e_pv_da_mat = np.concatenate((np.expand_dims(e_pv_da_grad,axis=1),np.expand_dims(e_pv_da_grad,axis=1),np.ones((num_areas,num_pops-num_e_pops))),axis=1)\n",
    "\n",
    "    # SST-->dendrite strength increases with dopamine (Gao et al., J Neurosci, 2003)\n",
    "    # To remove effect of dopamine on PV-->E connections, while keeping other dopamine effects, set d1_occ here = 0\n",
    "    e_sst_da_grad = (parameters['g_e_sst_min'] + d1_occ*d1_grad*(parameters['g_e_sst_max'] - parameters['g_e_sst_min']))/parameters['g_e_sst_min']\n",
    "    e_sst_da_mat = np.concatenate((np.expand_dims(e_sst_da_grad,axis=1),np.expand_dims(e_sst_da_grad,axis=1)),axis=1)\n",
    "\n",
    "    # High levels of D1 receptor stimulation engage an outward M-channel, reducing excitability (Arnsten et al., Neurobio. Stress., 2019)\n",
    "    # To remove effect of dopamine on the M-channel, while keeping other dopamine effects, set d1_occ here = 0\n",
    "    m_da_grad = sigmoid_DA(d1_occ*d1_grad,parameters['midpoint_m'],parameters['slope_m']).reshape(num_areas,1)\n",
    "\n",
    "    return(pops, num_pops, num_e_pops, num_areas, e_grad, g_adapt, ampa_frac, nmda_frac, J_nmda, J_ampa, \n",
    "          J_gaba, J_gaba_dend, W_superficial, W_deep, lr_targets, nmda_da_grad, e_pv_da_mat, e_sst_da_mat, m_da_grad,g_m,lr_targets_FEF,d1_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_vta_connectivity(parameters,c_VTA_DA_E1_now,c_VTA_DA_E2_now):\n",
    "\n",
    "    # set VTA parameters\n",
    "    I_background_vta = np.array([parameters['I_background_da_vta'],parameters['I_background_i_vta']])  * brian2.nA\n",
    "    # # # Long-range strengths to VTA\n",
    "    # g_VTA_DA_ctx_E2 = 0.03 \n",
    "    # g_VTA_DA_ctx_E1 = 0.005    \n",
    "    # # g_VTA_DA_ctx_E0 = 0.03\n",
    "    # # g_VTA_E_ctx  = 0.00   \n",
    "    # g_VTA_I_ctx_E2  = 0.01   \n",
    "    # g_VTA_I_ctx_E1  = 0.002  \n",
    "\n",
    "    # scale the cortex to vta synapses\n",
    "    g_VTA_DA_ctx_E1 = parameters['g_VTA_DA_ctx_E_scale']*c_VTA_DA_E1_now\n",
    "    g_VTA_DA_ctx_E2 = parameters['g_VTA_DA_ctx_E_scale']*c_VTA_DA_E2_now\n",
    "    g_VTA_I_ctx_E1 = parameters['g_VTA_I_ctx_E_scale']*c_VTA_DA_E1_now\n",
    "    g_VTA_I_ctx_E2 = parameters['g_VTA_I_ctx_E_scale']*c_VTA_DA_E2_now\n",
    "\n",
    "\n",
    "    W_vta_ctx = np.array([[g_VTA_DA_ctx_E1,g_VTA_I_ctx_E1],\n",
    "                          [g_VTA_DA_ctx_E2,g_VTA_I_ctx_E2]])\n",
    "\n",
    "    J_vta_local = np.array([[0,parameters['g_vta_da_I']],\n",
    "                             [0, 0 ]]) *brian2.nA\n",
    "\n",
    "    num_vta_pops = 2\n",
    "    pops_vta = ['DA','I']\n",
    "    return(W_vta_ctx,J_vta_local,num_vta_pops,pops_vta,I_background_vta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_variables(PARAMS,num_areas,num_pops,num_e_pops,area_list_SLN,stim_order):\n",
    "\n",
    "    # Initialise\n",
    "    num_iterations = int(PARAMS['trial_length']/PARAMS['dt'])\n",
    "\n",
    "    # Choose initial values for rates and synapse variables\n",
    "    R0 = np.matlib.repmat(np.array([PARAMS['r_0_e'],PARAMS['r_0_e'],0,0,PARAMS['r_0_e'],PARAMS['r_0_e'],PARAMS['r_0_e'],PARAMS['r_0_e'],PARAMS['r_0_e']]), num_areas, 1) * brian2.Hz\n",
    "    R = np.zeros((num_iterations,num_areas,num_pops)) * brian2.Hz\n",
    "    R[0,:,:] = R0\n",
    "\n",
    "    s_nmda = np.zeros((num_iterations,num_areas,num_pops))\n",
    "    s_ampa = np.zeros((num_iterations,num_areas,num_pops))\n",
    "    s_gaba = np.zeros((num_iterations,num_areas,num_pops))\n",
    "    s_gaba_dend = np.zeros((num_iterations,num_areas,num_pops))\n",
    "    s_adapt = np.zeros((num_iterations,num_areas,num_pops))\n",
    "    s_nmda_stp = np.zeros((num_iterations,num_areas,num_pops))\n",
    "    s_ampa_stp = np.zeros((num_iterations,num_areas,num_pops))\n",
    "    x = np.zeros((num_iterations,num_areas,num_e_pops))\n",
    "    x[0,:,:] = PARAMS['x0']*np.ones((num_areas,num_e_pops))\n",
    "    u = np.zeros((num_iterations,num_areas,num_e_pops))\n",
    "    u[0,:,:] = PARAMS['u0']*np.ones((num_areas,num_e_pops))\n",
    "\n",
    "    \n",
    "    # # Preassign external inputs\n",
    "    I_ext    = np.zeros((num_iterations,num_areas,num_pops)) * brian2.amp\n",
    "\n",
    "    \n",
    "    if stim_order == 1:\n",
    "        # Let's apply external stimulation to V1 populations E1 & E2\n",
    "        I_ext[int(PARAMS['stim_on']/PARAMS['dt']):int(PARAMS['stim_off']/PARAMS['dt']),area_list_SLN.index('V1'),pops.index('E1dend')] = PARAMS['stim_strength']\n",
    "        I_ext[int(PARAMS['distract_on']/PARAMS['dt']):int(PARAMS['distract_off']/PARAMS['dt']),area_list_SLN.index('V1'),pops.index('E2dend')] = PARAMS['stim_strength']\n",
    "    elif stim_order == 2:\n",
    "        # Let's apply external stimulation to V1 populations E1 & E2\n",
    "        I_ext[int(PARAMS['stim_on']/PARAMS['dt']):int(PARAMS['stim_off']/PARAMS['dt']),area_list_SLN.index('V1'),pops.index('E1dend')] = PARAMS['stim_strength']\n",
    "        I_ext[int(PARAMS['distract_on']/PARAMS['dt']):int(PARAMS['distract_off']/PARAMS['dt']),area_list_SLN.index('V1'),pops.index('E2dend')] = PARAMS['stim_strength']\n",
    "    \n",
    "    I_ext[int(PARAMS['ping_on']/PARAMS['dt']):int(PARAMS['ping_off']/PARAMS['dt']),area_list_SLN.index('V1'),[pops.index('E1dend'),pops.index('E2dend')]] = PARAMS['stim_strength']\n",
    "\n",
    "#     reward    = np.zeros((num_iterations,num_vta_pops)) * brian2.amp\n",
    "    \n",
    "#     # Let's apply the positive reward as inhibition to VTA GABA cells (see Soden et al., Nat Neurosci, 2020)\n",
    "#     reward[int(PARAMS['reward_on']/PARAMS['dt']):int(PARAMS['reward_off']/PARAMS['dt']),pops_vta.index('I')] = PARAMS['reward_strength']\n",
    "\n",
    "# #     # Let's apply the negative reward as inhibition to VTA DA cells (\n",
    "#     reward[int(PARAMS['reward_on']/PARAMS['dt']):int(PARAMS['reward_off']/PARAMS['dt']),pops_vta.index('DA')] = PARAMS['reward_strength']\n",
    "\n",
    "    \n",
    "    # Create matrices in which we can store the currents\n",
    "    I_lr_nmda    =  np.zeros((num_iterations,num_areas,num_pops)) * brian2.pA\n",
    "    I_lr_ampa    =  np.zeros((num_iterations,num_areas,num_pops)) * brian2.pA\n",
    "    I_local_nmda =  np.zeros((num_iterations,num_areas,num_pops)) * brian2.pA\n",
    "    I_local_ampa =  np.zeros((num_iterations,num_areas,num_pops)) * brian2.pA\n",
    "    I_local_gaba =  np.zeros((num_iterations,num_areas,num_pops)) * brian2.pA\n",
    "    I_soma_dend  =  np.zeros((num_iterations,num_areas,num_pops)) * brian2.pA\n",
    "    I_total      =  np.zeros((num_iterations,num_areas,num_pops)) * brian2.pA\n",
    "    I_exc_dend   = np.zeros((num_iterations,num_areas,num_e_pops)) * brian2.pA\n",
    "    I_inh_dend   = np.zeros((num_iterations,num_areas,num_e_pops)) * brian2.pA\n",
    "    I_local_gaba_dend =  np.zeros((num_iterations,num_areas,num_e_pops)) * brian2.pA\n",
    "    I_adapt = np.zeros((num_iterations,num_areas,num_pops)) * brian2.pA\n",
    "\n",
    "    # preassign variables VTA\n",
    "    I_lr_nmda_vta = np.zeros((num_iterations,num_vta_pops)) * brian2.pA   \n",
    "    I_lr_ampa_vta = np.zeros((num_iterations,num_vta_pops)) * brian2.pA\n",
    "    I_local_nmda_vta = np.zeros((num_iterations,num_vta_pops)) * brian2.pA   \n",
    "    I_local_ampa_vta = np.zeros((num_iterations,num_vta_pops)) * brian2.pA   \n",
    "    I_local_gaba_vta = np.zeros((num_iterations,num_vta_pops)) * brian2.pA    \n",
    "    total_vta_input  = np.zeros((num_iterations,num_vta_pops)) * brian2.pA\n",
    "    R_vta = np.zeros((num_iterations,num_vta_pops)) * brian2.Hz\n",
    "    s_nmda_vta  = np.zeros((num_iterations,num_vta_pops))\n",
    "    s_ampa_vta  = np.zeros((num_iterations,num_vta_pops))\n",
    "    s_gaba_vta  = np.zeros((num_iterations,num_vta_pops))\n",
    "    dyn_da_rel_ctx  = np.zeros((num_iterations))\n",
    "    dyn_da_rel_vta  = np.zeros((num_iterations))\n",
    "\n",
    "\n",
    "    \n",
    "    # Define background inputs\n",
    "    I_0 = np.zeros((num_areas,num_pops)) * brian2.pA\n",
    "    I_0[:,[pops.index('E1soma'),pops.index('E2soma')]] = PARAMS['I_background_e']\n",
    "    I_0[:,[pops.index('E1dend'),pops.index('E2dend')]] = PARAMS['I_background_dend']\n",
    "    I_0[:,[pops.index('PV'),pops.index('SST1'),pops.index('SST2'),pops.index('VIP1'),pops.index('VIP2')]] = PARAMS['I_background_i']\n",
    "\n",
    "    # Let's set up the noise. We will model the noise as an Ornstein-Uhlenbeck process.\n",
    "    # Gaussian noise. mean 0, std 1. Dims: timesteps, local populations, areas\n",
    "    eta = np.random.normal(loc=0.0, scale=1.0, size=(num_iterations,num_areas,num_pops))\n",
    "\n",
    "    # prepare the right hand side of the above equation\n",
    "    noise_rhs = eta*((np.sqrt(PARAMS['tau_ampa']*np.power(PARAMS['std_noise'],2))*np.sqrt(PARAMS['dt']))/PARAMS['tau_ampa'])\n",
    "    noise_rhs[:,:,2:4] = 0 # remove noise from dendrites\n",
    "    I_noise = np.zeros((num_areas , num_pops )) *brian2.pA\n",
    "\n",
    "    return(num_iterations,R,s_nmda,s_ampa,s_gaba,s_gaba_dend,s_adapt\n",
    "           ,I_ext,I_lr_nmda,I_lr_ampa,I_local_nmda,I_local_ampa,I_local_gaba\n",
    "           ,I_soma_dend,I_total,I_exc_dend,I_inh_dend,I_local_gaba_dend,I_adapt\n",
    "           ,I_0,I_noise,noise_rhs,I_lr_nmda_vta,I_lr_ampa_vta,I_local_nmda_vta\n",
    "           ,I_local_ampa_vta,I_local_gaba_vta,total_vta_input,R_vta,s_nmda_vta\n",
    "           ,s_ampa_vta,s_gaba_vta,dyn_da_rel_ctx,dyn_da_rel_vta,s_nmda_stp,s_ampa_stp,x,u)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " def large_scale_da_model(pops, num_pops, num_e_pops, num_areas, e_grad, g_adapt, ampa_frac, nmda_frac\n",
    "                          , J_nmda, J_ampa, J_gaba, J_gaba_dend, W_superficial, W_deep, lr_targets\n",
    "                          , nmda_da_grad, e_pv_da_mat, e_sst_da_mat, m_da_grad,num_iterations,R,s_nmda\n",
    "                          ,s_ampa,s_gaba,s_gaba_dend,s_adapt\n",
    "                          ,I_ext,I_lr_nmda,I_lr_ampa,I_local_nmda,I_local_ampa,I_local_gaba\n",
    "                          ,I_soma_dend,I_total,I_exc_dend,I_inh_dend,I_local_gaba_dend,I_adapt\n",
    "                          ,I_0,I_noise,noise_rhs,parameters,lr_targets_FEF,I_lr_nmda_vta,I_lr_ampa_vta\n",
    "                          ,I_local_nmda_vta,I_local_ampa_vta,I_local_gaba_vta,total_vta_input,R_vta\n",
    "                          ,s_nmda_vta,s_ampa_vta,s_gaba_vta,dyn_da_rel_ctx,dyn_da_rel_vta,I_background_vta,W_vta_ctx\n",
    "                          ,J_vta_local,d1_grad,s_nmda_stp,s_ampa_stp,x,u):\n",
    "    for i_t in range(1,num_iterations):\n",
    "            \n",
    "        # translate DA release to D1R occupancy \n",
    "        d1_occ = sigmoid_DA(dyn_da_rel_ctx[i_t-1],parameters['midpoint_d1occ'],parameters['slope_d1occ'])\n",
    "\n",
    "        # strength of excitatory currents through NMDA receptors increases with dopamine (Seamans et al., PNAS, 2001)\n",
    "        # To remove effect of dopamine on NMDA, while keeping other dopamine effects, set d1_occ here = 0\n",
    "        nmda_da_grad = 1 + parameters['g_nmda_da']*sigmoid_DA(d1_occ*np.expand_dims(d1_grad,axis=1),parameters['midpoint_nmda_da'],parameters['slope_nmda_da'])\n",
    "\n",
    "        # PV-->soma strength decreases with dopamine (Gao et al., J Neurosci, 2003)\n",
    "        # To remove effect of dopamine on PV-->E connections, while keeping other dopamine effects, set d1_occ here = 0\n",
    "        e_pv_da_grad = (parameters['g_e_pv_max'] + d1_occ*d1_grad*(parameters['g_e_pv_min'] - parameters['g_e_pv_max']))/parameters['g_e_pv_min']\n",
    "        e_pv_da_mat = np.concatenate((np.expand_dims(e_pv_da_grad,axis=1),np.expand_dims(e_pv_da_grad,axis=1),np.ones((num_areas,num_pops-num_e_pops))),axis=1)\n",
    "\n",
    "        # SST-->dendrite strength increases with dopamine (Gao et al., J Neurosci, 2003)\n",
    "        # To remove effect of dopamine on PV-->E connections, while keeping other dopamine effects, set d1_occ here = 0\n",
    "        e_sst_da_grad = (parameters['g_e_sst_min'] + d1_occ*d1_grad*(parameters['g_e_sst_max'] - parameters['g_e_sst_min']))/parameters['g_e_sst_min']\n",
    "        e_sst_da_mat = np.concatenate((np.expand_dims(e_sst_da_grad,axis=1),np.expand_dims(e_sst_da_grad,axis=1)),axis=1)\n",
    "\n",
    "        # High levels of D1 receptor stimulation engage an outward M-channel, reducing excitability (Arnsten et al., Neurobio. Stress., 2019)\n",
    "        # To remove effect of dopamine on the M-channel, while keeping other dopamine effects, set d1_occ here = 0\n",
    "        m_da_grad = sigmoid_DA(d1_occ*d1_grad,parameters['midpoint_m'],parameters['slope_m']).reshape(num_areas,1)\n",
    "\n",
    "        # update noise - dims = num local pops x num areas\n",
    "        I_noise = I_noise + -I_noise*(parameters['dt']/parameters['tau_ampa']) + noise_rhs[i_t-1,:,:]\n",
    "\n",
    "        # Long range NMDA to E populations \n",
    "        I_lr_nmda[i_t-1,:,:4]   = ((e_grad*parameters['mu_ee']*nmda_da_grad)*W_superficial).dot(s_nmda[i_t-1,:,:2]).dot(nmda_frac[:4]*lr_targets[:4,:].T)\n",
    "        # Long range NMDA to I populations \n",
    "        I_lr_nmda[i_t-1,:,4:]   = parameters['mu_ie']*e_grad*nmda_da_grad*(W_deep.dot(s_nmda[i_t-1,:,:2])).dot(nmda_frac[4:]*lr_targets[4:,:].T)\n",
    "        # Long range NMDA to I populations in FEF\n",
    "        I_lr_nmda[i_t-1,[area_list_SLN.index('8m'),area_list_SLN.index('8l')],4:]   = parameters['mu_ie']*e_grad[[area_list_SLN.index('8m'),area_list_SLN.index('8l')]]*nmda_da_grad[[area_list_SLN.index('8m'),area_list_SLN.index('8l')]]*(W_deep[[area_list_SLN.index('8m'),area_list_SLN.index('8l')],:].dot(s_nmda[i_t-1,:,:2])).dot(nmda_frac[4:]*lr_targets_FEF[4:,:].T)\n",
    "        \n",
    "        \n",
    "        # Long range AMPA to E populations \n",
    "        I_lr_ampa[i_t-1,:,:4]   = ((e_grad*parameters['mu_ee'])*W_superficial).dot(s_ampa[i_t-1,:,:2]).dot(ampa_frac[:4]*lr_targets[:4,:].T)\n",
    "        # Long range AMPA to I populations \n",
    "        I_lr_ampa[i_t-1,:,4:]   = parameters['mu_ie']*e_grad*(W_deep.dot(s_ampa[i_t-1,:,:2])).dot(ampa_frac[4:]*lr_targets[4:,:].T)\n",
    "        # Long range AMPA to I populations in FEF\n",
    "        I_lr_ampa[i_t-1,[area_list_SLN.index('8m'),area_list_SLN.index('8l')],4:]   = parameters['mu_ie']*e_grad[[area_list_SLN.index('8m'),area_list_SLN.index('8l')]]*(W_deep[[area_list_SLN.index('8m'),area_list_SLN.index('8l')],:].dot(s_ampa[i_t-1,:,:2])).dot(ampa_frac[4:]*lr_targets_FEF[4:,:].T)\n",
    "        \n",
    "        \n",
    "        # local NMDA\n",
    "        I_local_nmda[i_t-1,:,:] = nmda_frac*nmda_da_grad*e_grad*J_nmda.dot(s_nmda[i_t-1,:,:].T).T\n",
    "\n",
    "        # local AMPA\n",
    "        I_local_ampa[i_t-1,:,:] = ampa_frac*e_grad*J_ampa.dot(s_ampa[i_t-1,:,:].T).T\n",
    "\n",
    "        # sum up all the local GABA current onto E and I cell somas\n",
    "        I_local_gaba[i_t-1,:,:] = e_pv_da_mat*(J_gaba.dot(s_gaba[i_t-1,:,:].T).T)\n",
    "\n",
    "        # sum up all the local GABA current onto dendrites\n",
    "        I_local_gaba_dend[i_t-1,:,:] = e_sst_da_mat*(J_gaba_dend.dot(s_gaba_dend[i_t-1,:,:].T).T)\n",
    "\n",
    "        # calculate the dendrite-to-soma current\n",
    "        I_exc_dend[i_t-1,:,:] = I_local_nmda[i_t-1,:,2:4] + I_lr_nmda[i_t-1,:,2:4] + I_local_ampa[i_t-1,:,2:4] + I_lr_ampa[i_t-1,:,2:4] +I_0[:,2:4] + I_ext[i_t-1,:,2:4] + I_noise[:,2:4]\n",
    "\n",
    "        I_inh_dend[i_t-1,:,:] = I_local_gaba_dend[i_t-1,:,:] \n",
    "\n",
    "        I_soma_dend[i_t-1,:,:2]  = dendrite_input_output(I_exc_dend[i_t-1,:,:],I_inh_dend[i_t-1,:,:],parameters)\n",
    "\n",
    "        # adaptation current\n",
    "#         I_adapt[i_t-1,:,:] = (g_adapt+g_m*m_da_grad)*s_adapt[i_t-1,:,:]\n",
    "        I_adapt[i_t-1,:,:] = g_adapt*s_adapt[i_t-1,:,:]\n",
    "\n",
    "        # Define total input current as sum of local NMDA & GABA inputs, with background and external currents, \n",
    "        # noise and long-range NMDA inputs, and an adaptation current\n",
    "        I_total[i_t-1,:,:] = I_local_nmda[i_t-1,:,:] + I_local_ampa[i_t-1,:,:] +  I_local_gaba[i_t-1,:,:] + I_0 + I_ext[i_t-1,:,:] + I_noise + I_lr_nmda[i_t-1,:,:] + I_lr_ampa[i_t-1,:,:] + I_soma_dend[i_t-1,:,:] + I_adapt[i_t-1,:,:] \n",
    "\n",
    "        # calculate current inputs to VTA\n",
    "        # inputs to DA\n",
    "        I_lr_nmda_vta[i_t-1,0]   = np.sum([s_nmda[i_t-1,:,:2].dot(W_vta_ctx[:,0])],axis=1) *brian2.nA\n",
    "        I_lr_ampa_vta[i_t-1,0]   = np.sum([s_ampa[i_t-1,:,:2].dot(W_vta_ctx[:,0])],axis=1) *brian2.nA\n",
    "        # inputs to inhibitory neurons in VTA\n",
    "        I_lr_nmda_vta[i_t-1,1]   = np.sum([s_nmda_stp[i_t-1,:,:2].dot(W_vta_ctx[:,1])],axis=1) *brian2.nA\n",
    "        I_lr_ampa_vta[i_t-1,1]   = np.sum([s_ampa_stp[i_t-1,:,:2].dot(W_vta_ctx[:,1])],axis=1) *brian2.nA\n",
    "       \n",
    "        I_local_gaba_vta[i_t-1,:]      = J_vta_local.dot(s_gaba_vta[i_t-1,:])\n",
    "\n",
    "\n",
    "        total_vta_input[i_t-1,:] =    I_background_vta + I_lr_nmda_vta[i_t-1,:] + I_lr_ampa_vta[i_t-1,:] + I_local_nmda_vta[i_t-1,:] + I_local_ampa_vta[i_t-1,:] + I_local_gaba_vta[i_t-1,:]\n",
    "\n",
    "        \n",
    "        # Update the firing rates of the two excitatory populations.\n",
    "        R[i_t,:,:2] = R[i_t-1,:,:2] + parameters['dt']*current_to_frequency(I_total[i_t-1,:,:2],'E',parameters)/parameters['tau_ampa'] -parameters['dt']*R[i_t-1,:,:2]/parameters['tau_ampa']\n",
    "\n",
    "        # Update the firing rates of the PV population. \n",
    "        R[i_t,:,4] =  R[i_t-1,:,4] + parameters['dt']*current_to_frequency(I_total[i_t-1,:,4],'PV',parameters)/parameters['tau_ampa'] -parameters['dt']*R[i_t-1,:,4]/parameters['tau_ampa']\n",
    "\n",
    "        # Update the firing rates of the SST populations. \n",
    "        R[i_t,:,5:7] =  R[i_t-1,:,5:7] + parameters['dt']*current_to_frequency(I_total[i_t-1,:,5:7],'SST',parameters)/parameters['tau_ampa'] -parameters['dt']*R[i_t-1,:,5:7]/parameters['tau_ampa']\n",
    "\n",
    "        # Update the firing rates of the VIP populations. \n",
    "        R[i_t,:,7:] =  R[i_t-1,:,7:] +  parameters['dt']*current_to_frequency(I_total[i_t-1,:,7:],'VIP',parameters)/parameters['tau_ampa'] -parameters['dt']*R[i_t-1,:,7:]/parameters['tau_ampa']\n",
    "\n",
    "        # Update the firing rates of the DA and excitatory populations.\n",
    "        R_vta[i_t,0] = R_vta[i_t-1,0] + parameters['dt']*current_to_frequency(total_vta_input[i_t-1,0],'E',parameters)/parameters['tau_ampa'] -parameters['dt']*R_vta[i_t-1,0]/parameters['tau_ampa']\n",
    "\n",
    "        # Update the firing rates of the inhibitory population.\n",
    "        R_vta[i_t,1] = R_vta[i_t-1,1] + parameters['dt']*current_to_frequency(total_vta_input[i_t-1,1],'PV',parameters)/parameters['tau_ampa'] -parameters['dt']*R_vta[i_t-1,1]/parameters['tau_ampa']\n",
    "        \n",
    "        # Update the NMDA synapses\n",
    "        s_nmda[i_t,:,:2] = s_nmda[i_t-1,:,:2] + parameters['dt']*NMDA_deriv(s_nmda[i_t-1,:,:2],R[i_t,:,:2],parameters)\n",
    "\n",
    "        # Update the AMPA synapses\n",
    "        s_ampa[i_t,:,:2] = s_ampa[i_t-1,:,:2] + parameters['dt']*AMPA_deriv(s_ampa[i_t-1,:,:2],R[i_t,:,:2],parameters)\n",
    "\n",
    "        # Update the facilitation variable\n",
    "        u[i_t,:,:] = u[i_t-1,:,:] + parameters['dt']*STF_deriv(R[i_t,:,:2],u[i_t-1,:,:],parameters)\n",
    "\n",
    "        # Update the depression variable\n",
    "        x[i_t,:,:] = x[i_t-1,:,:] + parameters['dt']*STD_deriv(R[i_t,:,:2],x[i_t-1,:,:],u[i_t-1,:,:],parameters)\n",
    "\n",
    "        # Update the NMDA synapses\n",
    "        s_nmda_stp[i_t,:,:2] = s_nmda_stp[i_t-1,:,:2] + parameters['dt']*NMDA_deriv_STP(s_nmda_stp[i_t-1,:,:2],R[i_t,:,:2],parameters,u[i_t,:,:])\n",
    "\n",
    "        # Update the AMPA synapses\n",
    "        s_ampa_stp[i_t,:,:2] = s_ampa_stp[i_t-1,:,:2] + parameters['dt']*AMPA_deriv_STP(s_ampa_stp[i_t-1,:,:2],R[i_t,:,:2],parameters,u[i_t,:,:])\n",
    "        \n",
    "        # Update the GABA synapses onto the somata\n",
    "        s_gaba[i_t,:,4:] = s_gaba[i_t-1,:,4:] + parameters['dt']*GABA_deriv(s_gaba[i_t-1,:,4:],R[i_t,:,4:],parameters,'soma')\n",
    "\n",
    "        # Update the GABA synapses onto the dendrites\n",
    "        s_gaba_dend[i_t,:,4:] = s_gaba_dend[i_t-1,:,4:] + parameters['dt']*GABA_deriv(s_gaba_dend[i_t-1,:,4:],R[i_t,:,4:],parameters,'dendrite')\n",
    "\n",
    "        # Update the adaptation variable\n",
    "        s_adapt[i_t,:,:] = s_adapt[i_t-1,:,:] + parameters['dt']*adaptation_deriv(s_adapt[i_t-1,:,:],R[i_t,:,:],parameters)\n",
    "\n",
    "#         # Update the NMDA synapses\n",
    "#         s_nmda_vta[i_t,1:3] = s_nmda_vta[i_t-1,1:3] + parameters['dt']*NMDA_deriv(s_nmda_vta[i_t-1,1:3],R_vta[i_t,1:3],parameters)\n",
    "\n",
    "#         # Update the AMPA synapses\n",
    "#         s_ampa_vta[i_t,1:3] = s_ampa_vta[i_t-1,1:3] + parameters['dt']*AMPA_deriv(s_ampa_vta[i_t-1,1:3],R_vta[i_t,1:3],parameters)\n",
    "\n",
    "        # Update the GABA synapses onto the somata\n",
    "        s_gaba_vta[i_t,1] = s_gaba_vta[i_t-1,1] + parameters['dt']*GABA_deriv(s_gaba_vta[i_t-1,1],R_vta[i_t,1],parameters,'soma')\n",
    "\n",
    "        # release dopamine based on the firing rate of dopamine neurons\n",
    "        dyn_da_rel_ctx[i_t] = dyn_da_rel_ctx[i_t-1] + parameters['dt']*DAconc_deriv(dyn_da_rel_ctx[i_t-1],R_vta[i_t,0],parameters,'cortex')\n",
    "        \n",
    "        # release dopamine based on the firing rate of dopamine neurons\n",
    "        dyn_da_rel_vta[i_t] = dyn_da_rel_vta[i_t-1] + parameters['dt']*DAconc_deriv(dyn_da_rel_vta[i_t-1],R_vta[i_t,0],parameters,'vta')\n",
    "        \n",
    "        \n",
    "        \n",
    "    return(R,dyn_da_rel_ctx,dyn_da_rel_vta,x,u,R_vta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement reward based learning at the E-->DA synapses in the VTA according to the simplified Soltani & Wang rule\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Update E-->DA & I weights in VTA as follows:\n",
    "$$ g_{j,i}(t+1) = g_{D0}c_{i}(t+1)$$\n",
    "\n",
    "where $i \\epsilon {E1, E2}$ and $j \\epsilon {DA,I}$\n",
    "\n",
    "If E1 is selected & rewarded\n",
    "$$c(t+1) = c(t) + \\alpha(1 - c(t)) $$\n",
    "\n",
    "If E1 is selected & not rewarded\n",
    "$$c(t+1) = c(t) - \\alpha(c(t)) $$\n",
    "\n",
    "E1 is chosen if \n",
    "$$\\sum_{i \\epsilon FPN} \\frac{R_{E1,[i]}}{n} > \\sum_{i \\epsilon FPN} \\frac{R_{E2,[i]}}{n} $$\n",
    "\n",
    "where n is the number of areas in the fronto-parietal network and $\\alpha$ is the learning rate. E2 is chosen otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_based_learning(R,R_vta,rewarded_stimulus,parameters,persistent_activity_areas,c_VTA_DA_E1,c_VTA_DA_E2):\n",
    "        num_iterations = parameters['trial_length']/parameters['dt']\n",
    "        ping_on_timestep = int(parameters['ping_on']/parameters['dt'])\n",
    "        ping_off_timestep = int(parameters['ping_off']/parameters['dt'])\n",
    "        # Calculate the average delay period activity in excitatory population 1 in all the areas that show persistent activity experimentally\n",
    "        population1_ping_activity = np.mean(R[ping_on_timestep:ping_off_timestep,np.argwhere(persistent_activity_areas)[:,0],0])\n",
    "        # Now do the same for population 2\n",
    "        population2_ping_activity = np.mean(R[ping_on_timestep:ping_off_timestep,np.argwhere(persistent_activity_areas)[:,0],1])\n",
    "\n",
    "            \n",
    "        if rewarded_stimulus == 1:\n",
    "            if population1_ping_activity>population2_ping_activity:\n",
    "                reward = 1\n",
    "                \n",
    "                c_VTA_DA_E1 = c_VTA_DA_E1 + parameters['learning_rate_up']*(1 - c_VTA_DA_E1)\n",
    "            else:\n",
    "                reward = 0\n",
    "                c_VTA_DA_E2 = c_VTA_DA_E2 - parameters['learning_rate_down']*(c_VTA_DA_E2)\n",
    "\n",
    "        elif rewarded_stimulus == 2:\n",
    "            if population1_ping_activity<population2_ping_activity:\n",
    "                reward = 1\n",
    "                c_VTA_DA_E2 = c_VTA_DA_E2 + parameters['learning_rate_up']*(1 - c_VTA_DA_E2)\n",
    "\n",
    "            else:\n",
    "                reward = 0\n",
    "                c_VTA_DA_E1 = c_VTA_DA_E1 - parameters['learning_rate_down']*(c_VTA_DA_E1)\n",
    "\n",
    "        return(c_VTA_DA_E1,c_VTA_DA_E2,reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_areas(start_time,end_time,num_areas,area_list_SLN,R,parameters,pops_to_show,trial):\n",
    "    fig=plt.figure(figsize=(16,90), dpi= 80, facecolor='w', edgecolor='k')\n",
    "    plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "    for i in range(1,num_areas+1):\n",
    "        ax = plt.subplot(num_areas,2,i)\n",
    "        ax.set_title(area_list_SLN[i-1])\n",
    "        # Plot the rates for the E1 soma\n",
    "        plt.subplots_adjust(hspace = 1)\n",
    "        if True in (pops == 'E1' for pops in pops_to_show):\n",
    "            # Plot the rates for the E1 soma\n",
    "            plt.plot(np.arange((start_time-1)*brian2.second,(end_time-1)*brian2.second,PARAMS['dt']),R[trial,np.arange(int(start_time/PARAMS['dt']),int(end_time/PARAMS['dt']),1),i-1,0],color='r')\n",
    "        if True in (pops == 'E2' for pops in pops_to_show):\n",
    "            # Plot the rates for the E2 soma\n",
    "            plt.plot(np.arange((start_time-1)*brian2.second,(end_time-1)*brian2.second,PARAMS['dt']),R[trial,np.arange(int(start_time/PARAMS['dt']),int(end_time/PARAMS['dt']),1),i-1,1],color='b')\n",
    "        if True in (pops == 'PV' for pops in pops_to_show):\n",
    "            # Plot the rates for the PV population\n",
    "            plt.plot(np.arange((start_time-1)*brian2.second,(end_time-1)*brian2.second,PARAMS['dt']),R[trial,np.arange(int(start_time/PARAMS['dt']),int(end_time/PARAMS['dt']),1),i-1,4],color='#1b7837')\n",
    "        if True in (pops == 'SST1' for pops in pops_to_show):\n",
    "            # Plot the rates for the SST1 population\n",
    "            plt.plot(np.arange((start_time-1)*brian2.second,(end_time-1)*brian2.second,PARAMS['dt']),R[trial,np.arange(int(start_time/PARAMS['dt']),int(end_time/PARAMS['dt']),1),i-1,5],color='#b35806')\n",
    "        if True in (pops == 'SST2' for pops in pops_to_show):\n",
    "            # Plot the rates for the SST2 population\n",
    "            plt.plot(np.arange((start_time-1)*brian2.second,(end_time-1)*brian2.second,PARAMS['dt']),R[trial,np.arange(int(start_time/PARAMS['dt']),int(end_time/PARAMS['dt']),1),i-1,6],color='#b35806')\n",
    "        if True in (pops == 'VIP1' for pops in pops_to_show):\n",
    "            # Plot the rates for the VIP1 population\n",
    "            plt.plot(np.arange((start_time-1)*brian2.second,(end_time-1)*brian2.second,PARAMS['dt']),R[trial,np.arange(int(start_time/PARAMS['dt']),int(end_time/PARAMS['dt']),1),i-1,7],color='#542788')\n",
    "        if True in (pops == 'VIP2' for pops in pops_to_show):\n",
    "            # Plot the rates for the VIP2 population\n",
    "            plt.plot(np.arange((start_time-1)*brian2.second,(end_time-1)*brian2.second,PARAMS['dt']),R[trial,np.arange(int(start_time/PARAMS['dt']),int(end_time/PARAMS['dt']),1),i-1,8],color='#542788')\n",
    "\n",
    "        # Plot the stimulation time\n",
    "        plt.plot([parameters['stim_on']-1*brian2.second,parameters['stim_off']-1*brian2.second],[np.max(R[trial,:,i-1,:2]+0.05*np.max(R[trial,:,i-1,:2])),np.max(R[trial,:,i-1,:2]+0.05*np.max(R[trial,:,i-1,:2]))],color='r',linewidth=5.0)\n",
    "\n",
    "        # Plot the distractor time\n",
    "        plt.plot([parameters['distract_on']-1*brian2.second,parameters['distract_off']-1*brian2.second],[np.max(R[trial,:,i-1,:2]+0.05*np.max(R[trial,:,i-1,:2])),np.max(R[trial,:,i-1,:2]+0.05*np.max(R[trial,:,i-1,:2]))],color='b',linewidth=5.0)\n",
    "\n",
    "        # Plot the reward time\n",
    "        plt.plot([parameters['ping_on']-1*brian2.second,parameters['ping_off']-1*brian2.second],[np.max(R[trial,:,i-1,:2]+0.05*np.max(R[trial,:,i-1,:2])),np.max(R[trial,:,i-1,:2]+0.05*np.max(R[trial,:,i-1,:2]))],color='y',linewidth=5.0)\n",
    "\n",
    "        \n",
    "        # place text above the black line\n",
    "        axes = plt.gca()\n",
    "        if i==1:\n",
    "            axes.text(0.15, 1.2,'External stimulation to', transform=axes.transAxes, fontsize=10, verticalalignment='top')\n",
    "\n",
    "        plt.legend(pops_to_show)\n",
    "        plt.xlabel('time (s)')\n",
    "        plt.ylabel('firing rate (Hz)')\n",
    "        plt.ylim(0, 40) \n",
    "\n",
    "\n",
    "    # os.system('say \"finished\"')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_area(start_time,end_time,num_areas,area_list_SLN,R,parameters,pops_to_show,area_to_show,filename,trial):\n",
    "\n",
    "    i = area_list_SLN.index(area_to_show)+1\n",
    "\n",
    "    fig=plt.figure(figsize=(4,2), dpi= 80, facecolor='w', edgecolor='k')\n",
    "    plt.rcParams.update({'font.size': 25})\n",
    "\n",
    "#     plt.title(area_to_show)\n",
    "    if True in (pops == 'E1' for pops in pops_to_show):\n",
    "        # Plot the rates for the E1 soma\n",
    "        plt.plot(np.arange((start_time-1)*brian2.second,(end_time-1)*brian2.second,PARAMS['dt']),R[trial,np.arange(int(start_time/PARAMS['dt']),int(end_time/PARAMS['dt']),1),i-1,0],color='r')\n",
    "    if True in (pops == 'E2' for pops in pops_to_show):\n",
    "        # Plot the rates for the E2 soma\n",
    "        plt.plot(np.arange((start_time-1)*brian2.second,(end_time-1)*brian2.second,PARAMS['dt']),R[trial,np.arange(int(start_time/PARAMS['dt']),int(end_time/PARAMS['dt']),1),i-1,1],color='b')\n",
    "    if True in (pops == 'PV' for pops in pops_to_show):\n",
    "        # Plot the rates for the PV population\n",
    "        plt.plot(np.arange((start_time-1)*brian2.second,(end_time-1)*brian2.second,PARAMS['dt']),R[trial,np.arange(int(start_time/PARAMS['dt']),int(end_time/PARAMS['dt']),1),i-1,4],color='#1b7837')\n",
    "    if True in (pops == 'SST1' for pops in pops_to_show):\n",
    "        # Plot the rates for the SST1 population\n",
    "        plt.plot(np.arange((start_time-1)*brian2.second,(end_time-1)*brian2.second,PARAMS['dt']),R[trial,np.arange(int(start_time/PARAMS['dt']),int(end_time/PARAMS['dt']),1),i-1,5],color='#b35806')\n",
    "    if True in (pops == 'SST2' for pops in pops_to_show):\n",
    "        # Plot the rates for the SST2 population\n",
    "        plt.plot(np.arange((start_time-1)*brian2.second,(end_time-1)*brian2.second,PARAMS['dt']),R[trial,np.arange(int(start_time/PARAMS['dt']),int(end_time/PARAMS['dt']),1),i-1,6],color='#b35806')\n",
    "    if True in (pops == 'VIP1' for pops in pops_to_show):\n",
    "        # Plot the rates for the VIP1 population\n",
    "        plt.plot(np.arange((start_time-1)*brian2.second,(end_time-1)*brian2.second,PARAMS['dt']),R[trial,np.arange(int(start_time/PARAMS['dt']),int(end_time/PARAMS['dt']),1),i-1,7],color='#542788')\n",
    "    if True in (pops == 'VIP2' for pops in pops_to_show):\n",
    "        # Plot the rates for the VIP2 population\n",
    "        plt.plot(np.arange((start_time-1)*brian2.second,(end_time-1)*brian2.second,PARAMS['dt']),R[trial,np.arange(int(start_time/PARAMS['dt']),int(end_time/PARAMS['dt']),1),i-1,8],color='#542788')\n",
    "\n",
    "    axes = plt.gca()\n",
    "#     axes.text(0.1, 1.03,'cue', transform=axes.transAxes, fontsize=20, verticalalignment='top',color='r')\n",
    "#     axes.text(0.3, 1.03,'distractor', transform=axes.transAxes, fontsize=20, verticalalignment='top',color='b')\n",
    "    # Plot the stimulation time\n",
    "    plt.plot([parameters['stim_on']-6*brian2.second,parameters['stim_off']-6*brian2.second],[np.max(R[trial,:,i-1,5:]+0.05*np.max(R[trial,:,i-1,5:])),np.max(R[trial,:,i-1,5:]+0.05*np.max(R[trial,:,i-1,5:]))],color='r',linewidth=5.0)\n",
    "    # Plot the distractor time\n",
    "    plt.plot([parameters['distract_on']-6*brian2.second,parameters['distract_off']-6*brian2.second],[np.max(R[trial,:,i-1,5:]+0.05*np.max(R[trial,:,i-1,5:])),np.max(R[trial,:,i-1,5:]+0.05*np.max(R[trial,:,i-1,5:]))],color='b',linewidth=5.0)\n",
    "\n",
    "    # place text above the black line\n",
    "    # Shrink current axis by 20%\n",
    "\n",
    "#     plt.legend(pops_to_show,loc=(0.9,0.8),fontsize=15)\n",
    "#     plt.xlabel('time (s)')\n",
    "#     plt.ylabel('firing rate (Hz)')\n",
    "    plt.ylim(0, 50) \n",
    "\n",
    "    # Hide the right and top spines\n",
    "    axes.spines['right'].set_visible(False)\n",
    "    axes.spines['top'].set_visible(False)\n",
    "\n",
    "    # Only show ticks on the left and bottom spines\n",
    "    axes.yaxis.set_ticks_position('left')\n",
    "    axes.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "    fig.savefig(filename+'.pdf', dpi=300,bbox_inches='tight',transparent=True)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Run large-scale working memory model\n",
    "num_trials = 90\n",
    "num_iterations = int(PARAMS['trial_length']/PARAMS['dt'])\n",
    "\n",
    "rewards = np.zeros((num_trials))\n",
    "c_VTA_DA_E1 = PARAMS['c_VTA_DA_E1_init']\n",
    "c_VTA_DA_E2 = PARAMS['c_VTA_DA_E2_init']\n",
    "\n",
    "stimulus_order_all_trials = np.random.randint(1,3,num_trials)\n",
    "\n",
    "# Load in the anatomical data\n",
    "(sln, fln, hierarchy, area_list_SLN,\n",
    "        df_fln, df_sln, d1_density_raw, spine_count_raw, df_raw_anatomy,persistent_activity_areas) = load_anatomy()\n",
    "\n",
    "\n",
    "# Prepare all the connectivity matrices for the cortex\n",
    "(pops, num_pops, num_e_pops, num_areas, e_grad, g_adapt, ampa_frac, nmda_frac\n",
    " , J_nmda, J_ampa, J_gaba, J_gaba_dend, W_superficial, W_deep, lr_targets\n",
    " , nmda_da_grad, e_pv_da_mat, e_sst_da_mat, m_da_grad,g_m,lr_targets_FEF,d1_grad) = prepare_connectivity(PARAMS,spine_count_raw,fln,sln,d1_density_raw)\n",
    "\n",
    "# Prepare all the connectivity matrices for the VTA\n",
    "(W_vta_ctx,J_vta_local,num_vta_pops,pops_vta,I_background_vta) = prepare_vta_connectivity(PARAMS,c_VTA_DA_E1,c_VTA_DA_E2)\n",
    "\n",
    "# Initialise all the variables\n",
    "(num_iterations,R,s_nmda,s_ampa,s_gaba,s_gaba_dend,s_adapt\n",
    "           ,I_ext,I_lr_nmda,I_lr_ampa,I_local_nmda,I_local_ampa,I_local_gaba\n",
    "           ,I_soma_dend,I_total,I_exc_dend,I_inh_dend,I_local_gaba_dend,I_adapt\n",
    "           ,I_0,I_noise,noise_rhs,I_lr_nmda_vta,I_lr_ampa_vta,I_local_nmda_vta\n",
    "           ,I_local_ampa_vta,I_local_gaba_vta,total_vta_input,R_vta,s_nmda_vta\n",
    "           ,s_ampa_vta,s_gaba_vta,dyn_da_rel_ctx,dyn_da_rel_vta,s_nmda_stp,s_ampa_stp,x,u) = initialise_variables(PARAMS,num_areas,num_pops,num_e_pops,area_list_SLN,stimulus_order_all_trials[0])\n",
    "\n",
    "# reward the first stimulus on the first 5 trials, and then switch the rule\n",
    "rewarded_stim = np.concatenate((np.concatenate((np.ones((int(num_trials/3),1)), 2*np.ones((int(num_trials/3),1))), axis=0) , np.ones((int(num_trials/3),1))), axis=0)\n",
    "# rewarded_stim = np.ones(1)\n",
    "R_all_trials = np.zeros((num_trials,num_iterations,num_areas,num_pops)) * brian2.Hz\n",
    "R_vta_all_trials = np.zeros((num_trials,num_iterations,num_vta_pops)) * brian2.Hz\n",
    "dyn_da_rel_all_trials = np.zeros((num_trials,num_iterations))\n",
    "\n",
    "\n",
    "for current_trial in range(1,num_trials+1):\n",
    "\n",
    "    print(current_trial)\n",
    "    \n",
    "    # Prepare all the connectivity matrices for the cortex\n",
    "    (pops, num_pops, num_e_pops, num_areas, e_grad, g_adapt, ampa_frac, nmda_frac\n",
    "     , J_nmda, J_ampa, J_gaba, J_gaba_dend, W_superficial, W_deep, lr_targets\n",
    "     , nmda_da_grad, e_pv_da_mat, e_sst_da_mat, m_da_grad,g_m,lr_targets_FEF,d1_grad) = prepare_connectivity(PARAMS,spine_count_raw,fln,sln,d1_density_raw)\n",
    "\n",
    "    # Prepare all the connectivity matrices for the VTA\n",
    "    (W_vta_ctx,J_vta_local,num_vta_pops,pops_vta,I_background_vta)  = prepare_vta_connectivity(PARAMS,c_VTA_DA_E1,c_VTA_DA_E2)\n",
    "\n",
    "    # Initialise all the variables\n",
    "    (num_iterations,R,s_nmda,s_ampa,s_gaba,s_gaba_dend,s_adapt\n",
    "           ,I_ext,I_lr_nmda,I_lr_ampa,I_local_nmda,I_local_ampa,I_local_gaba\n",
    "           ,I_soma_dend,I_total,I_exc_dend,I_inh_dend,I_local_gaba_dend,I_adapt\n",
    "           ,I_0,I_noise,noise_rhs,I_lr_nmda_vta,I_lr_ampa_vta,I_local_nmda_vta\n",
    "           ,I_local_ampa_vta,I_local_gaba_vta,total_vta_input,R_vta,s_nmda_vta\n",
    "           ,s_ampa_vta,s_gaba_vta,dyn_da_rel_ctx,dyn_da_rel_vta,s_nmda_stp,s_ampa_stp,x,u) = initialise_variables(PARAMS,num_areas,num_pops,num_e_pops,area_list_SLN,stimulus_order_all_trials[current_trial-1])\n",
    "\n",
    "    # Run the simulation\n",
    "    (R,dyn_da_rel_ctx,dyn_da_rel_vta,x,u,R_vta) = large_scale_da_model(pops, num_pops, num_e_pops, num_areas, e_grad, g_adapt, ampa_frac, nmda_frac\n",
    "                          , J_nmda, J_ampa, J_gaba, J_gaba_dend, W_superficial, W_deep, lr_targets\n",
    "                          , nmda_da_grad, e_pv_da_mat, e_sst_da_mat, m_da_grad,num_iterations,R,s_nmda\n",
    "                          ,s_ampa,s_gaba,s_gaba_dend,s_adapt\n",
    "                          ,I_ext,I_lr_nmda,I_lr_ampa,I_local_nmda,I_local_ampa,I_local_gaba\n",
    "                          ,I_soma_dend,I_total,I_exc_dend,I_inh_dend,I_local_gaba_dend,I_adapt\n",
    "                          ,I_0,I_noise,noise_rhs,PARAMS,lr_targets_FEF,I_lr_nmda_vta,I_lr_ampa_vta\n",
    "                          ,I_local_nmda_vta,I_local_ampa_vta,I_local_gaba_vta,total_vta_input,R_vta\n",
    "                          ,s_nmda_vta,s_ampa_vta,s_gaba_vta,dyn_da_rel_ctx,dyn_da_rel_vta,I_background_vta,W_vta_ctx\n",
    "                          ,J_vta_local,d1_grad,s_nmda_stp,s_ampa_stp,x,u)\n",
    "\n",
    "    \n",
    "    # Update weights in VTA based on outcome of the trial\n",
    "    (c_VTA_DA_E1,c_VTA_DA_E2,reward) = reward_based_learning(R,R_vta,rewarded_stim[current_trial-1],PARAMS,persistent_activity_areas,c_VTA_DA_E1,c_VTA_DA_E2)\n",
    "    \n",
    "    rewards[current_trial-1] = reward\n",
    "    R_all_trials[current_trial-1,:,:,:] = R\n",
    "    R_vta_all_trials[current_trial-1,:,:] = R_vta\n",
    "    dyn_da_rel_all_trials[current_trial-1,:] = dyn_da_rel_ctx\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pops_to_plot = ['E1','E2']\n",
    "start_time = 5.5\n",
    "end_time = 13\n",
    "trial = 34\n",
    "plot_all_areas(start_time,end_time,num_areas,area_list_SLN,R_all_trials,PARAMS,pops_to_plot,trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove the run-in time \n",
    "# R_all_trials_short = copy.deepcopy(R_all_trials[:,10000:,:,:])\n",
    "# R_vta_all_trials_short = copy.deepcopy(R_vta_all_trials[:,10000:,:])\n",
    "# dyn_da_rel_all_trials_short = copy.deepcopy(dyn_da_rel_all_trials[:,10000:])\n",
    "\n",
    "# data = {}\n",
    "\n",
    "# data.update({'R': R_all_trials_short}) # firing rates cortex\n",
    "# data.update({'R_vta': R_vta_all_trials_short}) # firing rates VTA\n",
    "# data.update({'da_rel': dyn_da_rel_all_trials_short}) # cortical dopamine availability\n",
    "# data.update({'rewards': rewards}) # reward history\n",
    "\n",
    "\n",
    "# sio.savemat('model_outputs/cortex_vta_learning_soltani_90trials.mat', data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
